0:legend.position = "top",
0:legend.title = element_blank(),
0:text = element_text(size=10),
0:axis.text.y = element_text(size = 10),
0:panel.border = element_rect(colour = "black", fill = NA),
0:strip.text.x = element_text(face = "bold",hjust = 0),
0:axis.text.x = element_text(angle=90),
0:strip.background.x = element_blank(),
0:axis.title.y = element_text(size = 11),
0:plot.margin = unit(c(0, 1, 0, 0), "cm"),
0:legend.box.margin = margin(0,-10,-10,-10),
0:legend.margin=margin(0,0,0,0),
0:panel.spacing.x = unit(0.2, "in"),
0:panel.background = element_rect(
0:fill = "white"),
0:panel.spacing = unit(0.5, "lines"))
0:ggsave("figures/phyto_density_plots_max_doy_allyears.jpg", width=7, height=4)
0:#------------------------------------------------------------------------#
0:# effect size fig for zoops
0:zoop_scenarios_summary <- zoop_scenarios |>
0:dplyr::group_by(taxon, year, scenario) |>
0:dplyr::summarise(mean = mean(value),
0:sd = sd(value),
0:size = n())
0:# function to calculate the pooled sd
0:pooled_sd <- function(group_sizes, group_sds) {
0:# Ensure that the inputs are of the same length
0:if (length(group_sizes) != length(group_sds)) {
0:stop("group_sizes and group_sds must be of the same length.")
0:}
0:# Calculate pooled standard deviation
0:sqrt(
0:sum((group_sizes - 1) * (group_sds^2)) /
0:(sum(group_sizes) - length(group_sizes))
0:)
0:}
0:zoop_effect_size <- zoop_scenarios_summary |>
0:dplyr::group_by(taxon, year) |>
0:dplyr::summarise(plus1 = (mean[scenario=="plus1"] -
0:mean[scenario=="baseline"]) /
0:pooled_sd(group_sizes = c(size[scenario=="baseline"],
0:size[scenario=="plus1"]),
0:group_sd = c(sd[scenario=="baseline"],
0:sd[scenario=="plus1"])),
0:plus5 = (mean[scenario=="plus5"] -
0:mean[scenario=="baseline"]) /
0:pooled_sd(group_sizes = c(size[scenario=="baseline"],
0:size[scenario=="plus1"]),
0:group_sd = c(sd[scenario=="baseline"],
0:sd[scenario=="plus5"])),
0:plus10 = (mean[scenario=="plus10"] -
0:mean[scenario=="baseline"]) /
0:pooled_sd(group_sizes = c(size[scenario=="baseline"],
0:size[scenario=="plus1"]),
0:group_sd = c(sd[scenario=="baseline"],
0:sd[scenario=="plus10"]))) |>
0:tidyr::pivot_longer(cols = -c(taxon,year),
0:names_to = "scenario",
0:values_to = "value") |> dplyr::ungroup() |>
0:dplyr::group_by(taxon,scenario) |>
0:dplyr::mutate(sd = sd(value))
0:View(zoop_effect_size)
0:# plot effect sizes for each scenario
0:ggplot(zoop_effect_size, aes(x=value,
0:y=factor(scenario,levels=c("plus1","plus5","plus10")),
0:color=as.factor(year))) +
0:geom_point(size=3) + theme_bw() + xlab("Effect Size") + ylab("") +
0:facet_wrap(~taxon, scales="free_x") +
0:#scale_color_manual("", values = c("#c6a000","#c85b00","#680000"),
0:#                   breaks = c("plus1","plus5","plus10"),
0:#                   labels = c("+1C","+5C","+10C")) +
0:geom_vline(xintercept = 0, linetype = "dashed") +
0:#geom_errorbar(aes(xmin = value - sd, xmax = value + sd),
0:#              width = 0.2) +
0:theme(panel.grid.major = element_blank(),
0:panel.grid.minor = element_blank(),
0:axis.line = element_line(colour = "black"),
0:legend.background = element_blank(),
0:legend.position = "right",
0:text = element_text(size=10),
0:panel.border = element_rect(colour = "black", fill = NA),
0:strip.background.x = element_blank(),
0:plot.margin = unit(c(0.2, 0.1, 0, 0), "cm"),
0:legend.margin = margin(c(-10,-1,-10,-10)),
0:panel.spacing.x = unit(0.1, "in"),
0:panel.background = element_rect(
0:fill = "white"),
0:panel.spacing.y = unit(0, "lines"))
0:# plot effect sizes for each scenario
0:ggplot(zoop_effect_size, aes(x=value,
0:y=factor(scenario,levels=c("plus1","plus5","plus10")),
0:color=scenario)) +
0:geom_point(size=3) + theme_bw() + xlab("Effect Size") + ylab("") +
0:facet_wrap(~taxon, scales="free_x") +
0:scale_color_manual("", values = c("#c6a000","#c85b00","#680000"),
0:breaks = c("plus1","plus5","plus10"),
0:labels = c("+1C","+5C","+10C")) +
0:geom_vline(xintercept = 0, linetype = "dashed") +
0:geom_errorbar(aes(xmin = value - sd, xmax = value + sd),
0:width = 0.2) +
0:theme(panel.grid.major = element_blank(),
0:panel.grid.minor = element_blank(),
0:axis.line = element_line(colour = "black"),
0:legend.background = element_blank(),
0:legend.position = "right",
0:text = element_text(size=10),
0:panel.border = element_rect(colour = "black", fill = NA),
0:strip.background.x = element_blank(),
0:plot.margin = unit(c(0.2, 0.1, 0, 0), "cm"),
0:legend.margin = margin(c(-10,-1,-10,-10)),
0:panel.spacing.x = unit(0.1, "in"),
0:panel.background = element_rect(
0:fill = "white"),
0:panel.spacing.y = unit(0, "lines"))
0:zoop_effect_size |>
0:dplyr::group_by(taxon, scenario, sd) |>
0:dplyr::summarise(median = median(value))
0:zoop_effect_size |>
0:dplyr::group_by(taxon, scenario) |>
0:dplyr::summarise(median = median(value))
0:# plot median effect sizes for each scenario
0:zoop_effect_size |>
0:dplyr::group_by(taxon, scenario) |>
0:dplyr::summarise(median = median(value)) |>
0:ggplot() + geom_point(aes(x=median, y=factor(scenario,levels=c("plus1","plus5","plus10")),
0:color=scenario), size=3) +
0:theme_bw() + xlab("Effect Size") + ylab("") +
0:facet_wrap(~taxon, scales="free_x") +
0:scale_color_manual("", values = c("#c6a000","#c85b00","#680000"),
0:breaks = c("plus1","plus5","plus10"),
0:labels = c("+1C","+5C","+10C")) +
0:geom_vline(xintercept = 0, linetype = "dashed") +
0:geom_errorbar(aes(xmin = median - sd, xmax = median + sd),
0:width = 0.2) +
0:theme(panel.grid.major = element_blank(),
0:panel.grid.minor = element_blank(),
0:axis.line = element_line(colour = "black"),
0:legend.background = element_blank(),
0:legend.position = "right",
0:text = element_text(size=10),
0:panel.border = element_rect(colour = "black", fill = NA),
0:strip.background.x = element_blank(),
0:plot.margin = unit(c(0.2, 0.1, 0, 0), "cm"),
0:legend.margin = margin(c(-10,-1,-10,-10)),
0:panel.spacing.x = unit(0.1, "in"),
0:panel.background = element_rect(
0:fill = "white"),
0:panel.spacing.y = unit(0, "lines"))
0:# plot median effect sizes for each scenario
0:zoop_effect_size |>
0:dplyr::group_by(taxon, scenario, sd) |>
0:dplyr::summarise(median = median(value)) |>
0:ggplot() + geom_point(aes(x=median, y=factor(scenario,levels=c("plus1","plus5","plus10")),
0:color=scenario), size=3) +
0:theme_bw() + xlab("Effect Size") + ylab("") +
0:facet_wrap(~taxon, scales="free_x") +
0:scale_color_manual("", values = c("#c6a000","#c85b00","#680000"),
0:breaks = c("plus1","plus5","plus10"),
0:labels = c("+1C","+5C","+10C")) +
0:geom_vline(xintercept = 0, linetype = "dashed") +
0:geom_errorbar(aes(xmin = median - sd, xmax = median + sd),
0:width = 0.2) +
0:theme(panel.grid.major = element_blank(),
0:panel.grid.minor = element_blank(),
0:axis.line = element_line(colour = "black"),
0:legend.background = element_blank(),
0:legend.position = "right",
0:text = element_text(size=10),
0:panel.border = element_rect(colour = "black", fill = NA),
0:strip.background.x = element_blank(),
0:plot.margin = unit(c(0.2, 0.1, 0, 0), "cm"),
0:legend.margin = margin(c(-10,-1,-10,-10)),
0:panel.spacing.x = unit(0.1, "in"),
0:panel.background = element_rect(
0:fill = "white"),
0:panel.spacing.y = unit(0, "lines"))
0:zoop_effect_size |>
0:dplyr::group_by(taxon, scenario, sd) |>
0:dplyr::summarise(median = median(value))
0:# plot median effect sizes for each scenario
0:zoop_effect_size |>
0:dplyr::group_by(taxon, scenario, sd) |>
0:dplyr::summarise(median = median(value)) |>
0:ggplot() + geom_point(aes(x=median, y=factor(scenario,levels=c("plus1","plus5","plus10")),
0:color=scenario), size=3) +
0:theme_bw() + xlab("Effect Size") + ylab("") +
0:facet_wrap(~taxon, scales="free_x") +
0:scale_color_manual("", values = c("#c6a000","#c85b00","#680000"),
0:breaks = c("plus1","plus5","plus10"),
0:labels = c("+1C","+5C","+10C")) +
0:geom_vline(xintercept = 0, linetype = "dashed") +
0:geom_errorbar(aes(xmin = median - sd, xmax = median + sd),
0:width = 0.2) +
0:theme(panel.grid.major = element_blank(),
0:panel.grid.minor = element_blank(),
0:axis.line = element_line(colour = "black"),
0:legend.background = element_blank(),
0:legend.position = "right",
0:text = element_text(size=10),
0:panel.border = element_rect(colour = "black", fill = NA),
0:strip.background.x = element_blank(),
0:plot.margin = unit(c(0.2, 0.1, 0, 0), "cm"),
0:legend.margin = margin(c(-10,-1,-10,-10)),
0:panel.spacing.x = unit(0.1, "in"),
0:panel.background = element_rect(
0:fill = "white"),
0:panel.spacing.y = unit(0, "lines"))
0:# plot median effect sizes for each scenario
0:zoop_effect_size |>
0:dplyr::group_by(taxon, scenario, sd) |>
0:dplyr::summarise(median = median(value)) |>
0:ggplot() + geom_point(aes(x=median, y=factor(scenario,levels=c("plus1","plus5","plus10")),
0:color=scenario), size=3) +
0:theme_bw() + xlab("Effect Size") + ylab("") +
0:facet_wrap(~taxon, scales="free_x") +
0:scale_color_manual("", values = c("#c6a000","#c85b00","#680000"),
0:breaks = c("plus1","plus5","plus10"),
0:labels = c("+1C","+5C","+10C")) +
0:geom_vline(xintercept = 0, linetype = "dashed") +
0:geom_errorbar(aes(x = median, ymin = median - sd, ymax = median + sd),
0:width = 0.2) +
0:theme(panel.grid.major = element_blank(),
0:panel.grid.minor = element_blank(),
0:axis.line = element_line(colour = "black"),
0:legend.background = element_blank(),
0:legend.position = "right",
0:text = element_text(size=10),
0:panel.border = element_rect(colour = "black", fill = NA),
0:strip.background.x = element_blank(),
0:plot.margin = unit(c(0.2, 0.1, 0, 0), "cm"),
0:legend.margin = margin(c(-10,-1,-10,-10)),
0:panel.spacing.x = unit(0.1, "in"),
0:panel.background = element_rect(
0:fill = "white"),
0:panel.spacing.y = unit(0, "lines"))
0:# plot median effect sizes for each scenario
0:zoop_effect_size |>
0:dplyr::group_by(taxon, scenario, sd) |>
0:dplyr::summarise(median = median(value)) |>
0:ggplot() + geom_point(aes(x=median, y=factor(scenario,levels=c("plus1","plus5","plus10")),
0:color=scenario), size=3) +
0:theme_bw() + xlab("Effect Size") + ylab("") +
0:facet_wrap(~taxon, scales="free_x") +
0:scale_color_manual("", values = c("#c6a000","#c85b00","#680000"),
0:breaks = c("plus1","plus5","plus10"),
0:labels = c("+1C","+5C","+10C")) +
0:geom_vline(xintercept = 0, linetype = "dashed") +
0:geom_errorbarh(aes(y = factor(scenario, levels = c("plus1", "plus5", "plus10")),
0:xmin = median - sd, xmax = median + sd),
0:height = 0.2) +
0:theme(panel.grid.major = element_blank(),
0:panel.grid.minor = element_blank(),
0:axis.line = element_line(colour = "black"),
0:legend.background = element_blank(),
0:legend.position = "right",
0:text = element_text(size=10),
0:panel.border = element_rect(colour = "black", fill = NA),
0:strip.background.x = element_blank(),
0:plot.margin = unit(c(0.2, 0.1, 0, 0), "cm"),
0:legend.margin = margin(c(-10,-1,-10,-10)),
0:panel.spacing.x = unit(0.1, "in"),
0:panel.background = element_rect(
0:fill = "white"),
0:panel.spacing.y = unit(0, "lines"))
0:t <- zoop_effect_size |>
0:dplyr::group_by(taxon, scenario, sd) |>
0:dplyr::summarise(median = median(value))
0:View(t)
0:ggsave("figures/zoop_scenario_effect_size_sd.jpg", width=7, height=4)
0:# effect size fig for phytos
0:phyto_scenarios_summary <- phyto_scenarios |>
0:dplyr::group_by(taxon, scenario) |>
0:dplyr::summarise(mean = mean(value),
0:sd = sd(value),
0:size = n())
0:phyto_effect_size <- phyto_scenarios_summary |>
0:dplyr::group_by(taxon, year) |>
0:dplyr::summarise(plus1 = (mean[scenario=="plus1"] -
0:mean[scenario=="baseline"]) /
0:pooled_sd(group_sizes = c(size[scenario=="baseline"],
0:size[scenario=="plus1"]),
0:group_sd = c(sd[scenario=="baseline"],
0:sd[scenario=="plus1"])),
0:plus5 = (mean[scenario=="plus5"] -
0:mean[scenario=="baseline"]) /
0:pooled_sd(group_sizes = c(size[scenario=="baseline"],
0:size[scenario=="plus1"]),
0:group_sd = c(sd[scenario=="baseline"],
0:sd[scenario=="plus5"])),
0:plus10 = (mean[scenario=="plus10"] -
0:mean[scenario=="baseline"]) /
0:pooled_sd(group_sizes = c(size[scenario=="baseline"],
0:size[scenario=="plus1"]),
0:group_sd = c(sd[scenario=="baseline"],
0:sd[scenario=="plus10"]))) |>
0:tidyr::pivot_longer(cols = -c(taxon,year),
0:names_to = "scenario",
0:values_to = "value") |> dplyr::ungroup() |>
0:dplyr::group_by(taxon,scenario) |>
0:dplyr::mutate(sd = sd(value))
0:# effect size fig for phytos
0:phyto_scenarios_summary <- phyto_scenarios |>
0:dplyr::group_by(taxon, year, scenario) |>
0:dplyr::summarise(mean = mean(value),
0:sd = sd(value),
0:size = n())
0:phyto_effect_size <- phyto_scenarios_summary |>
0:dplyr::group_by(taxon, year) |>
0:dplyr::summarise(plus1 = (mean[scenario=="plus1"] -
0:mean[scenario=="baseline"]) /
0:pooled_sd(group_sizes = c(size[scenario=="baseline"],
0:size[scenario=="plus1"]),
0:group_sd = c(sd[scenario=="baseline"],
0:sd[scenario=="plus1"])),
0:plus5 = (mean[scenario=="plus5"] -
0:mean[scenario=="baseline"]) /
0:pooled_sd(group_sizes = c(size[scenario=="baseline"],
0:size[scenario=="plus1"]),
0:group_sd = c(sd[scenario=="baseline"],
0:sd[scenario=="plus5"])),
0:plus10 = (mean[scenario=="plus10"] -
0:mean[scenario=="baseline"]) /
0:pooled_sd(group_sizes = c(size[scenario=="baseline"],
0:size[scenario=="plus1"]),
0:group_sd = c(sd[scenario=="baseline"],
0:sd[scenario=="plus10"]))) |>
0:tidyr::pivot_longer(cols = -c(taxon,year),
0:names_to = "scenario",
0:values_to = "value") |> dplyr::ungroup() |>
0:dplyr::group_by(taxon,scenario) |>
0:dplyr::mutate(sd = sd(value))
0:# plot median effect sizes for each scenario
0:phyto_effect_size |>
0:dplyr::group_by(taxon, scenario, sd) |>
0:dplyr::summarise(median = median(value)) |>
0:ggplot() + geom_point(aes(x=median, y=factor(scenario,levels=c("plus1","plus5","plus10")),
0:color=scenario), size=3) +
0:theme_bw() + xlab("Effect Size") + ylab("") +
0:facet_wrap(~taxon, scales="free_x") +
0:scale_color_manual("", values = c("#c6a000","#c85b00","#680000"),
0:breaks = c("plus1","plus5","plus10"),
0:labels = c("+1C","+5C","+10C")) +
0:geom_vline(xintercept = 0, linetype = "dashed") +
0:geom_errorbarh(aes(y = factor(scenario, levels = c("plus1", "plus5", "plus10")),
0:xmin = median - sd, xmax = median + sd),
0:height = 0.2) +
0:theme(panel.grid.major = element_blank(),
0:panel.grid.minor = element_blank(),
0:axis.line = element_line(colour = "black"),
0:legend.background = element_blank(),
0:legend.position = "right",
0:text = element_text(size=10),
0:panel.border = element_rect(colour = "black", fill = NA),
0:strip.background.x = element_blank(),
0:plot.margin = unit(c(0.2, 0.1, 0, 0), "cm"),
0:legend.margin = margin(c(-10,-1,-10,-10)),
0:panel.spacing.x = unit(0.1, "in"),
0:panel.background = element_rect(
0:fill = "white"),
0:panel.spacing.y = unit(0, "lines"))
0:ggsave("figures/phyto_scenario_effect_size_sd.jpg", width=7, height=4)
0:getwd()
0:pacman::p_load(tidyverse)
0:pacman::p_load(tidyverse)
0:future_temp <- read.csv("analysis/MACA/maxtemp_rcp85.csv", skip=8) |>
0:rename(date = yyyy.mm.dd,
0:temp = tasmax_CCSM4_rcp85.K.) |>
0:mutate(temp = temp - 273.15,
0:date = as.Date(date))
0:future_temp <- read.csv("analysis/MACA/maxtemp_CCSM4_rcp85.csv", skip=8) |>
0:rename(date = yyyy.mm.dd,
0:temp = tasmax_CCSM4_rcp85.K.) |>
0:mutate(temp = temp - 273.15,
0:date = as.Date(date))
0:#quick plot of max temps from 2006-2099
0:ggplot(future_temp, aes(date, temp)) + geom_line() +
0:theme_bw()
0:#max temp for just 2020-2050 = 44.6C
0:max(future_temp$temp[future_temp$date>="2020-01-01" &
0:future_temp$date<="2051-01-01"])
0:future_temp_rcp4.5 <- read.csv("analysis/MACA/maxtemp_CCSM4_rcp45.csv", skip=8) |>
0:rename(date = yyyy.mm.dd,
0:temp = tasmax_CCSM4_rcp45.K.) |>
0:mutate(temp = temp - 273.15,
0:date = as.Date(date))
0:#quick plot of max temps from 2006-2099
0:ggplot(future_temp_rcp4.5, aes(date, temp)) + geom_line() +
0:theme_bw()
0:max(future_temp_rcp4.5$temp)
0:max(future_temp$temp)
0:#vs historical max temp from 1950-2005 ESM2M model
0:historical_temp_ESM2M <- read.csv("analysis/MACA/historical_temp_ESM2M.csv", skip=8) |>
0:rename(date = yyyy.mm.dd,
0:temp = tasmax_CCSM4_historical.K.) |>
0:mutate(temp = temp - 273.15,
0:date = as.Date(date))
0:#vs historical max temp from 1950-2005 ESM2M model
0:historical_temp_ESM2M <- read.csv("analysis/MACA/historical_temp_ESM2M.csv", skip=8) |>
0:rename(date = yyyy.mm.dd,
0:temp = tasmax_ESM2M_historical.K.) |>
0:mutate(temp = temp - 273.15,
0:date = as.Date(date))
0:historical_temp_ESM2M <- read.csv("analysis/MACA/historical_temp_ESM2M.csv", skip=8)
0:View(historical_temp_ESM2M)
0:#vs historical max temp from 1950-2005 ESM2M model
0:historical_temp_ESM2M <- read.csv("analysis/MACA/historical_temp_ESM2M.csv", skip=8) |>
0:rename(date = yyyy.mm.dd,
0:temp = tasmax_GFDL.ESM2M_historical.K.) |>
0:mutate(temp = temp - 273.15,
0:date = as.Date(date))
0:#vs historical max temp from 1950-2005 ESM2M model
0:historical_temp_ESM2M <- read.csv("analysis/MACA/historical_temp_ESM2M.csv", skip=8) |>
0:rename(date = yyyy.mm.dd,
0:temp = tasmax_GFDL.ESM2M_historical.K.) |>
0:mutate(temp = temp - 273.15,
0:date = as.Date(date))
0:#plot historical max temps
0:ggplot(historical_temp_ESM2M, aes(date, temp)) + geom_line() +
0:theme_bw()
0:#vs historical max temp from 1950-2005 ESM2G model
0:historical_temp_ESM2G <- read.csv("analysis/MACA/historical_temp_ESM2G.csv", skip=8) |>
0:rename(date = yyyy.mm.dd,
0:temp = tasmax_GFDL.ESM2G_historical.K.) |>
0:mutate(temp = temp - 273.15,
0:date = as.Date(date))
0:#plot historical max temps
0:ggplot(historical_temp_ESM2G, aes(date, temp)) + geom_line() +
0:theme_bw()
0:#vs historical max temp from 1950-2005 CCSM4 model
0:historical_temp_CCSM4 <- read.csv("analysis/MACA/historical_temp_CCSM4.csv", skip=8) |>
0:rename(date = yyyy.mm.dd,
0:temp = tasmax_CCSM4_historical.K.) |>
0:mutate(temp = temp - 273.15,
0:date = as.Date(date))
0:#plot historical max temps
0:ggplot(historical_temp_CCSM4, aes(date, temp)) + geom_line() +
0:theme_bw()
0:max(historical_temp_CCSM4)
0:max(historical_temp_CCSM4$temp)
0:max(historical_temp_ESM2G$temp)
0:max(historical_temp_ESM2M$temp)
0:pacman::p_load(tidyverse)
0:future_temp <- read.csv("analysis/MACA/maxtemp_CCSM4_rcp85.csv", skip=8) |>
0:rename(date = yyyy.mm.dd,
0:temp = tasmax_CCSM4_rcp85.K.) |>
0:mutate(temp = temp - 273.15,
0:date = as.Date(date))
0:#quick plot of max temps from 2006-2099
0:ggplot(future_temp, aes(date, temp)) + geom_line() +
0:theme_bw()
0:mean(future_temp$temp)
0:future_temp_rcp4.5 <- read.csv("analysis/MACA/maxtemp_CCSM4_rcp45.csv", skip=8) |>
0:rename(date = yyyy.mm.dd,
0:temp = tasmax_CCSM4_rcp45.K.) |>
0:mutate(temp = temp - 273.15,
0:date = as.Date(date))
0:mean(future_temp_rcp4.5$temp)
0:#vs historical max temp from 1950-2005 CCSM4 model
0:historical_temp_CCSM4 <- read.csv("analysis/MACA/historical_temp_CCSM4.csv", skip=8) |>
0:rename(date = yyyy.mm.dd,
0:temp = tasmax_CCSM4_historical.K.) |>
0:mutate(temp = temp - 273.15,
0:date = as.Date(date))
0:mean(historical_temp_CCSM4$temp)
0:#vs historical max temp from 1950-2005 ESM2M model
0:historical_temp_ESM2M <- read.csv("analysis/MACA/historical_temp_ESM2M.csv", skip=8) |>
0:rename(date = yyyy.mm.dd,
0:temp = tasmax_GFDL.ESM2M_historical.K.) |>
0:mutate(temp = temp - 273.15,
0:date = as.Date(date))
0:mean(historical_temp_ESM2M$temp)
0:#vs historical max temp from 1950-2005 ESM2G model
0:historical_temp_ESM2G <- read.csv("analysis/MACA/historical_temp_ESM2G.csv", skip=8) |>
0:rename(date = yyyy.mm.dd,
0:temp = tasmax_GFDL.ESM2G_historical.K.) |>
0:mutate(temp = temp - 273.15,
0:date = as.Date(date))
0:mean(historical_temp_ESM2G$temp)
0:future_temp_esm2m <- read.csv("analysis/MACA/maxtemp_ESM2M_rcp85.csv", skip=8) |>
0:rename(date = yyyy.mm.dd,
0:temp = tasmax_GFDL.ESM2M_rcp85.K.) |>
0:mutate(temp = temp - 273.15,
0:date = as.Date(date))
0:mean(future_temp_esm2m$temp)
0:future_temp_rcp4.5_esm2m <- read.csv("temp_scenarios/maxtemp_ESM2M_rcp45.csv", skip=8) |>
0:rename(date = yyyy.mm.dd,
0:temp = tasmax_GFDL.ESM2M_rcp45.K.) |>
0:mutate(temp = temp - 273.15,
0:date = as.Date(date))
0:future_temp_rcp4.5_esm2m <- read.csv("analysis/MACA/maxtemp_ESM2M_rcp45.csv", skip=8) |>
0:rename(date = yyyy.mm.dd,
0:temp = tasmax_GFDL.ESM2M_rcp45.K.) |>
0:mutate(temp = temp - 273.15,
0:date = as.Date(date))
0:mean(future_temp_rcp4.5_esm2m$temp)
0:future_temp_esm2g <- read.csv("temp_scenarios/maxtemp_ESM2G_rcp85.csv", skip=8) |>
0:rename(date = yyyy.mm.dd,
0:temp = tasmax_GFDL.ESM2G_rcp85.K.) |>
0:mutate(temp = temp - 273.15,
0:date = as.Date(date))
0:future_temp_esm2g <- read.csv("analysis/MACA/maxtemp_ESM2G_rcp85.csv", skip=8) |>
0:rename(date = yyyy.mm.dd,
0:temp = tasmax_GFDL.ESM2G_rcp85.K.) |>
0:mutate(temp = temp - 273.15,
0:date = as.Date(date))
0:mean(future_temp_esm2g$temp)
0:future_temp_rcp4.5_esm2g <- read.csv("analysis/MACA/maxtemp_ESM2G_rcp45.csv", skip=8) |>
0:rename(date = yyyy.mm.dd,
0:temp = tasmax_GFDL.ESM2G_rcp45.K.) |>
0:mutate(temp = temp - 273.15,
0:date = as.Date(date))
0:mean(future_temp_rcp4.5_esm2g$temp)
1733518411416:# run the model
1733518411416:sim_folder = "./sims/baseline"
1733518412057:GLM3r::run_glm(sim_folder)
1733519606502:sim_year
1733519608310:sim_year <- 2016
1733519611007:year_offset <- (sim_year - 2000) %% 8
1733519622163:obs_year <- 2015 + year_offset
1733519806864:# Define the observation period for cycling
1733519806865:obs_start_year <- 2015
1733519807086:obs_end_year <- 2022
1733519807783:obs_years <- seq(obs_start_year, obs_end_year)
1733519811327:# Set start and end dates
1733519811328:start_date <- as.POSIXct("2000-07-08 00:00:00", tz = "UTC")
1733519811490:end_date <- as.POSIXct("2022-05-04 00:00:00", tz = "UTC")
1733519811643:total_hours <- as.numeric(difftime(end_date, start_date, units = "hours")) + 1
1733519811848:total_days <- ceiling(as.numeric(difftime(end_date, start_date, units = "days")) + 1)
1733519812201:# Define the observation period for cycling
1733519812202:obs_start_year <- 2015
1733519812384:obs_end_year <- 2022
1733519812742:obs_years <- seq(obs_start_year, obs_end_year)
1733519814342:# Function to map simulation date to observation date
1733519814342:map_to_obs_date <- function(sim_date, obs, hourly = TRUE) {
1733519814342:# Get simulation year, month, day, and time
1733519814343:sim_year <- as.numeric(format(sim_date, "%Y"))
1733519814352:month_day <- format(sim_date, "%m-%d")
1733519814352:time <- if (hourly) format(sim_date, "%H:%M:%S") else "00:00:00"
1733519814353:# Define specific year mapping based on your description
1733519814353:year_map <- c("2000" = "2015", "2008" = "2015",
1733519814353:"2001" = "2016", "2009" = "2016",
1733519814353:"2002" = "2017", "2010" = "2017",
1733519814353:"2003" = "2018", "2011" = "2018",
1733519814353:"2004" = "2019", "2012" = "2019",
1733519814353:"2005" = "2020", "2013" = "2020",
1733519814354:"2006" = "2021", "2014" = "2021",
1733519814354:"2007" = "2022", "2015" = "2022")
1733519814354:# Map the simulation year to the observation year using the year_map
1733519814355:obs_year <- year_map[as.character(sim_year)]
1733519814355:# If simulation year is not in the mapping, return NA
1733519814355:if (is.null(obs_year)) {
1733519814355:return(NA)
1733519814356:}
1733519814356:# Adjust leap year dates (e.g., February 29th)
1733519814356:if ((obs_year == 2016 || obs_year == 2020) && month_day == "02-29") {
1733519814356:# If the observation year is a leap year and it's February 29, change to February 28
1733519814357:month_day <- "02-28"
1733519814357:}
1733519814357:# Construct observation date
1733519814357:obs_date <- as.POSIXct(paste0(obs_year, "-", month_day, " ", time),
1733519814358:format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
1733519814358:# If obs_date exceeds the final obs date (2022-05-04), adjust it
1733519814359:if (!is.na(obs_date) && obs_date > as.POSIXct("2022-05-04 23:59:59", tz = "UTC")) {
1733519814359:days_offset <- as.numeric(difftime(obs_date, as.POSIXct("2022-05-04", tz = "UTC"), units = "days"))
1733519814359:obs_date <- as.POSIXct("2016-05-05", tz = "UTC") + days_offset * 86400
1733519814360:}
1733519814360:# Apply correction for 2015 dates up to mid-2015
1733519814360:if (!is.na(obs_date) && obs_year == 2015 && obs_date >= as.POSIXct("2015-01-01", tz = "UTC") &&
1733519814361:obs_date <= as.POSIXct("2015-07-06 23:00:00", tz = "UTC")) {
1733519814361:obs_date <- as.POSIXct(paste0(2016, "-", month_day, " ", time), format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
1733519814361:}
1733519814363:# Check if obs_date is in obs data and return; if not, return NA
1733519814364:if (!is.na(obs_date) && obs_date %in% obs$time) {
1733519814365:return(obs_date)
1733519814365:} else {
1733519814365:if (hourly) {
1733519814366:cat("No match for obs_date:", sim_date, "\n")
1733519814366:}
1733519814366:return(NA)
1733519814366:}
1733519814367:}
1733519819727:scenario
1733519824533:#list of scenarios
1733519824534:scenario <- c("baseline","plus1","plus5","plus10")
1733519830171:for (i in 1:length(scenario))
1733519833181:i<- 1
1733519834959:# Step 1: Set file paths and update start date in the .nml file
1733519834960:scenario_nml_file <- file.path(paste0("./sims/", scenario[i], "/glm3.nml"))
1733519836061:scenario_nml_file
1733519853008:# Step 1: Set file paths and update start date in the .nml file
1733519853009:scenario_nml_file <- file.path(paste0("./sims/", scenario[i], "/glm3.nml"))
1733519853564:scenario_nml <- glmtools::read_nml(nml_file = scenario_nml_file)
1733519859629:# install glmtools
1733519859630:devtools::install_github("rqthomas/glmtools", force = TRUE)
1733519890080:# Step 1: Set file paths and update start date in the .nml file
1733519890081:scenario_nml_file <- file.path(paste0("./sims/", scenario[i], "/glm3.nml"))
1733519890573:scenario_nml <- glmtools::read_nml(nml_file = scenario_nml_file)
1733519893302:scenario_nml
1733519919040:scenario_nml <- glmtools::set_nml(scenario_nml, arg_name = "start",
1733519919041:arg_val = format(start_date, "%Y-%m-%d %H:%M:%S"))
1733519921882:View(scenario_nml)
1733519939659:glmtools::write_nml(scenario_nml, file = scenario_nml_file)
1733519944295:# Step 2: Adjust the met files
1733519944296:met_file <- if (scenario[i] == "baseline") {
1733519944296:paste0("sims/", scenario[i], "/inputs/met.csv")
1733519944297:} else {
1733519944297:paste0("sims/", scenario[i], "/inputs/met_", scenario[i], ".csv")
1733519944297:}
1733519950724:met <- read.csv(met_file) |>
1733519950725:dplyr::mutate(time = as.POSIXct(paste0(time, ":00"),
1733519950725:format = "%Y-%m-%d %H:%M:%S", tz = "UTC")) |>
1733519950725:dplyr::filter(time >= as.POSIXct("2015-07-08"))
1733519951589:# Generate the sequence of simulation dates
1733519951590:expanded_times <- seq(start_date, by = "hour", length.out = total_hours)
1733519956753:# Map simulation times to observation times
1733519956753:mapped_times <- vapply(expanded_times, function(sim_date) {
1733519956754:map_to_obs_date(sim_date, met)
1733519956754:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733520393402:# Function to map simulation date to observation date
1733520393404:map_to_obs_date <- function(sim_date, obs, hourly = TRUE) {
1733520440117:# Function to map simulation date to observation date
1733520440117:map_to_obs_date <- function(sim_date, obs, hourly = TRUE) {
1733520440118:# Get simulation year, month, day, and time
1733520440118:sim_year <- as.numeric(format(sim_date, "%Y"))
1733520440119:month_day <- format(sim_date, "%m-%d")
1733520440119:time <- if (hourly) format(sim_date, "%H:%M:%S") else "00:00:00"
1733520440120:# Simplified year mapping using modular arithmetic
1733520440121:obs_year <- 2015 + ((sim_year - 2000) %% 8)
1733520440122:# Adjust dates based on special cases for 2000, 2008, 2007, and 2015
1733520440123:if (sim_year == 2000 || sim_year == 2008) {
1733520440127:# For 2000 and 2008 -> 2015, dates before July 7th map to 2016
1733520440127:if (obs_year == 2015 && sim_date < as.POSIXct("2015-07-07 00:00:00", tz = "UTC")) {
1733520440131:obs_year <- 2016
1733520440131:}
1733520440132:}
1733520440132:if (sim_year == 2007 || sim_year == 2015) {
1733520440132:# For 2007 and 2015 -> 2022, dates after May 3rd map to 2016
1733520440132:if (obs_year == 2022 && sim_date >= as.POSIXct("2022-05-04 00:00:00", tz = "UTC")) {
1733520440133:obs_year <- 2016
1733520440133:}
1733520440134:}
1733520440134:# Adjust leap year dates (e.g., February 29th)
1733520440134:if ((obs_year == 2016 || obs_year == 2020) && month_day == "02-29") {
1733520440135:# If the observation year is a leap year and it's February 29, change to February 28
1733520440135:month_day <- "02-28"
1733520440135:}
1733520440136:# Construct observation date
1733520440136:obs_date <- as.POSIXct(paste0(obs_year, "-", month_day, " ", time),
1733520440136:format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
1733520440137:# If obs_date exceeds the final obs date (2022-05-04), adjust it
1733520440137:if (!is.na(obs_date) && obs_date > as.POSIXct("2022-05-04 23:59:59", tz = "UTC")) {
1733520440137:days_offset <- as.numeric(difftime(obs_date, as.POSIXct("2022-05-04", tz = "UTC"), units = "days"))
1733520440137:obs_date <- as.POSIXct("2016-05-05", tz = "UTC") + days_offset * 86400
1733520440138:}
1733520440138:# Apply correction for 2015 dates up to mid-2015
1733520440138:if (!is.na(obs_date) && obs_year == 2015 && obs_date >= as.POSIXct("2015-01-01", tz = "UTC") &&
1733520440139:obs_date <= as.POSIXct("2015-07-06 23:00:00", tz = "UTC")) {
1733520440139:obs_date <- as.POSIXct(paste0(2016, "-", month_day, " ", time), format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
1733520440139:}
1733520440141:# Check if obs_date is in obs data and return; if not, return NA
1733520440142:if (!is.na(obs_date) && obs_date %in% obs$time) {
1733520440143:return(obs_date)
1733520440143:} else {
1733520440144:if (hourly) {
1733520440144:cat("No match for obs_date:", sim_date, "\n")
1733520440146:}
1733520440147:return(NA)
1733520440148:}
1733520440149:}
1733520444485:# Get simulation year, month, day, and time
1733520444486:sim_year <- as.numeric(format(sim_date, "%Y"))
1733520446185:sim_year
1733520479277:sim_year <- 2015
1733520494177:# Simplified year mapping using modular arithmetic
1733520494178:obs_year <- 2015 + ((sim_year - 2000) %% 8)
1733520496189:obs_year
1733520842909:# Function to map simulation date to observation date
1733520842911:map_to_obs_date <- function(sim_date, obs, hourly = TRUE) {
1733520842911:# Ensure sim_date is of Date class if it does not contain time
1733520842915:sim_date <- as.Date(sim_date)
1733520842915:# Get simulation year and month/day
1733520842916:sim_year <- as.numeric(format(sim_date, "%Y"))
1733520842917:month_day <- format(sim_date, "%m-%d")
1733520842919:# Initialize observation year variable
1733520842920:obs_year <- sim_year
1733520842920:# Only map simulation years to observation years up until July 6, 2015
1733520842921:if (sim_date < as.Date("2015-07-07")) {
1733520842921:# Simplified year mapping using modular arithmetic for dates up to July 6, 2015
1733520842921:obs_year <- 2015 + ((sim_year - 2000) %% 8)
1733520842921:# Adjust dates based on special cases for 2000, 2008, 2007, and 2015
1733520842921:if (sim_year == 2000 || sim_year == 2008) {
1733520842922:# For 2000 and 2008 -> 2015, dates before July 7th map to 2016
1733520842922:if (obs_year == 2015 && sim_date < as.Date("2015-07-07")) {
1733520842922:obs_year <- 2016
1733520842922:}
1733520842922:}
1733520842922:if (sim_year == 2007 || sim_year == 2015) {
1733520842922:# For 2007 and 2015 -> 2022, dates after May 3rd map to 2016
1733520842922:if (obs_year == 2022 && sim_date >= as.Date("2022-05-04")) {
1733520842922:obs_year <- 2016
1733520842922:}
1733520842923:}
1733520842923:# Adjust leap year dates (e.g., February 29th)
1733520842923:if ((obs_year == 2016 || obs_year == 2020) && month_day == "02-29") {
1733520842923:# If the observation year is a leap year and it's February 29, change to February 28
1733520842923:month_day <- "02-28"
1733520842924:}
1733520842924:}
1733520842924:# After July 6, 2015, use the actual observation year
1733520842926:# Construct observation date
1733520842927:obs_date <- as.Date(paste0(obs_year, "-", month_day))
1733520842927:# If obs_date exceeds the final obs date (2022-05-04), adjust it
1733520842928:if (obs_date > as.Date("2022-05-04")) {
1733520842928:days_offset <- as.numeric(difftime(obs_date, as.Date("2022-05-04"), units = "days"))
1733520842928:obs_date <- as.Date("2016-05-05") + days_offset
1733520842928:}
1733520842929:# Apply correction for 2015 dates up to mid-2015
1733520842930:if (obs_year == 2015 && obs_date >= as.Date("2015-01-01") &&
1733520842930:obs_date <= as.Date("2015-07-06")) {
1733520842930:obs_date <- as.Date(paste0(2016, "-", month_day))
1733520842964:}
1733520842970:# Check if obs_date is in obs data and return; if not, return NA
1733520842988:if (!is.na(obs_date) && obs_date %in% obs$time) {
1733520842988:return(obs_date)
1733520842995:} else {
1733520842995:if (hourly) {
1733520842996:cat("No match for obs_date:", sim_date, "\n")
1733520842997:}
1733520842997:return(NA)
1733520842998:}
1733520842998:}
1733520848465:sim_date
1733520852267:sim_year
1733520855887:# Initialize observation year variable
1733520855888:obs_year <- sim_year
1733520863672:# Simplified year mapping using modular arithmetic for dates up to July 6, 2015
1733520863673:obs_year <- 2015 + ((sim_year - 2000) %% 8)
1733520897274:# Function to map simulation date to observation date
1733520897275:map_to_obs_date <- function(sim_date, obs, hourly = TRUE) {
1733520897275:# Ensure sim_date is of Date class if it does not contain time
1733520897276:sim_date <- as.Date(sim_date)
1733520897277:# Get simulation year and month/day
1733520897277:sim_year <- as.numeric(format(sim_date, "%Y"))
1733520897277:month_day <- format(sim_date, "%m-%d")
1733520897278:# Initialize observation year variable
1733520897279:obs_year <- sim_year
1733520897281:# Only map simulation years to observation years up until July 6, 2015
1733520897281:if (sim_date < as.Date("2015-07-07")) {
1733520897281:# Simplified year mapping using modular arithmetic for dates up to July 6, 2015
1733520897281:obs_year <- 2015 + ((sim_year - 2000) %% 8)
1733520897282:# Adjust dates based on special cases for 2000, 2008, 2007, and 2015
1733520897282:if (sim_year == 2000 || sim_year == 2008) {
1733520897282:# For 2000 and 2008 -> 2015, dates before July 7th map to 2016
1733520897282:if (obs_year == 2015 && sim_date < as.Date("2015-07-07")) {
1733520897282:obs_year <- 2016
1733520897283:}
1733520897283:}
1733520897283:if (sim_year == 2007 || sim_year == 2015) {
1733520897283:# For 2007 and 2015 -> 2022, dates after May 3rd map to 2016
1733520897284:if (obs_year == 2022 && sim_date >= as.Date("2022-05-04")) {
1733520897284:obs_year <- 2016
1733520897284:}
1733520897284:}
1733520897284:# Adjust leap year dates (e.g., February 29th)
1733520897285:if ((obs_year == 2016 || obs_year == 2020) && month_day == "02-29") {
1733520897285:# If the observation year is a leap year and it's February 29, change to February 28
1733520897285:month_day <- "02-28"
1733520897285:}
1733520897286:}
1733520897286:# After July 6, 2015, use the actual observation year
1733520897286:# Construct observation date
1733520897286:obs_date <- as.Date(paste0(obs_year, "-", month_day))
1733520897287:# If obs_date exceeds the final obs date (2022-05-04), adjust it
1733520897287:if (obs_date > as.Date("2022-05-04")) {
1733520897287:days_offset <- as.numeric(difftime(obs_date, as.Date("2022-05-04"), units = "days"))
1733520897287:obs_date <- as.Date("2016-05-05") + days_offset
1733520897288:}
1733520897288:# Apply correction for 2015 dates up to mid-2015
1733520897288:if (obs_year == 2015 && obs_date >= as.Date("2015-01-01") &&
1733520897288:obs_date <= as.Date("2015-07-06")) {
1733520897289:obs_date <- as.Date(paste0(2016, "-", month_day))
1733520897289:}
1733520897289:# Check if obs_date is in obs data and return; if not, return NA
1733520897290:if (!is.na(obs_date) && obs_date %in% obs$time) {
1733520897290:return(obs_date)
1733520897290:} else {
1733520897290:if (hourly) {
1733520897291:cat("No match for obs_date:", sim_date, "\n")
1733520897291:}
1733520897291:return(NA)
1733520897291:}
1733520897292:}
1733520900507:# Step 1: Set file paths and update start date in the .nml file
1733520900507:scenario_nml_file <- file.path(paste0("./sims/", scenario[i], "/glm3.nml"))
1733520901960:scenario_nml_file
1733520905921:# Step 2: Adjust the met files
1733520905921:met_file <- if (scenario[i] == "baseline") {
1733520905921:paste0("sims/", scenario[i], "/inputs/met.csv")
1733520905922:} else {
1733520905922:paste0("sims/", scenario[i], "/inputs/met_", scenario[i], ".csv")
1733520905922:}
1733520907884:met <- read.csv(met_file) |>
1733520907886:dplyr::mutate(time = as.POSIXct(paste0(time, ":00"),
1733520907886:format = "%Y-%m-%d %H:%M:%S", tz = "UTC")) |>
1733520907887:dplyr::filter(time >= as.POSIXct("2015-07-08"))
1733520946206:View(met)
1733520976064:# Function to map simulation date to observation date
1733520976065:map_to_obs_date <- function(sim_date, obs, hourly = TRUE) {
1733520976066:# Ensure sim_date is of Date class if it does not contain time
1733520976066:sim_date <- as.Date(sim_date)
1733520976066:# Get simulation year and month/day
1733520976067:sim_year <- as.numeric(format(sim_date, "%Y"))
1733520976077:month_day <- format(sim_date, "%m-%d")
1733520976078:# Initialize observation year variable
1733520976078:obs_year <- sim_year
1733520976079:# Only map simulation years to observation years up until July 7, 2015
1733520976080:if (sim_date < as.Date("2015-07-08")) {
1733520976080:# Simplified year mapping using modular arithmetic for dates up to July 7, 2015
1733520976081:obs_year <- 2015 + ((sim_year - 2000) %% 8)
1733520976082:# Adjust dates based on special cases for 2000, 2008, 2007, and 2015
1733520976083:if (sim_year == 2000 || sim_year == 2008) {
1733520976083:# For 2000 and 2008 -> 2015, dates before July 8th map to 2016
1733520976084:if (obs_year == 2015 && sim_date < as.Date("2015-07-08")) {
1733520976084:obs_year <- 2016
1733520976084:}
1733520976085:}
1733520976085:if (sim_year == 2007 || sim_year == 2015) {
1733520976085:# For 2007 and 2015 -> 2022, dates after May 3rd map to 2016
1733520976085:if (obs_year == 2022 && sim_date >= as.Date("2022-05-04")) {
1733520976086:obs_year <- 2016
1733520976086:}
1733520976086:}
1733520976087:# Adjust leap year dates (e.g., February 29th)
1733520976087:if ((obs_year == 2016 || obs_year == 2020) && month_day == "02-29") {
1733520976089:# If the observation year is a leap year and it's February 29, change to February 28
1733520976090:month_day <- "02-28"
1733520976090:}
1733520976091:}
1733520976093:# After July 6, 2015, use the actual observation year
1733520976093:# Construct observation date
1733520976093:obs_date <- as.Date(paste0(obs_year, "-", month_day))
1733520976094:# If obs_date exceeds the final obs date (2022-05-04), adjust it
1733520976095:if (obs_date > as.Date("2022-05-04")) {
1733520976095:days_offset <- as.numeric(difftime(obs_date, as.Date("2022-05-04"), units = "days"))
1733520976096:obs_date <- as.Date("2016-05-05") + days_offset
1733520976096:}
1733520976097:# Apply correction for 2015 dates up to mid-2015
1733520976097:if (obs_year == 2015 && obs_date >= as.Date("2015-01-01") &&
1733520976098:obs_date <= as.Date("2015-07-06")) {
1733520976098:obs_date <- as.Date(paste0(2016, "-", month_day))
1733520976099:}
1733520976100:# Check if obs_date is in obs data and return; if not, return NA
1733520976100:if (!is.na(obs_date) && obs_date %in% obs$time) {
1733520976101:return(obs_date)
1733520976102:} else {
1733520976102:if (hourly) {
1733520976102:cat("No match for obs_date:", sim_date, "\n")
1733520976103:}
1733520976103:return(NA)
1733520976103:}
1733520976104:}
1733520984249:# Step 2: Adjust the met files
1733520984250:met_file <- if (scenario[i] == "baseline") {
1733520984250:paste0("sims/", scenario[i], "/inputs/met.csv")
1733520984250:} else {
1733520984251:paste0("sims/", scenario[i], "/inputs/met_", scenario[i], ".csv")
1733520984251:}
1733520995767:met <- read.csv(met_file) |>
1733520995767:dplyr::mutate(time = as.POSIXct(paste0(time, ":00"),
1733520995768:format = "%Y-%m-%d %H:%M:%S", tz = "UTC")) |>
1733520995768:dplyr::filter(time >= as.POSIXct("2015-07-08"))
1733521004480:# Generate the sequence of simulation dates
1733521004481:expanded_times <- seq(start_date, by = "hour", length.out = total_hours)
1733521005739:# Map simulation times to observation times
1733521005740:mapped_times <- vapply(expanded_times, function(sim_date) {
1733521005740:map_to_obs_date(sim_date, met)
1733521005741:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733521477940:# Step 2: Adjust the met files
1733521477941:met_file <- if (scenario[i] == "baseline") {
1733521477941:paste0("sims/", scenario[i], "/inputs/met.csv")
1733521477942:} else {
1733521477942:paste0("sims/", scenario[i], "/inputs/met_", scenario[i], ".csv")
1733521477945:}
1733521482452:met <- read.csv(met_file) |>
1733521482454:dplyr::mutate(time = as.POSIXct(paste0(time, ":00"),
1733521482455:format = "%Y-%m-%d %H:%M:%S", tz = "UTC")) |>
1733521482456:dplyr::filter(time >= as.POSIXct("2015-07-08"))
1733521485141:# Generate the sequence of simulation dates
1733521485143:expanded_times <- seq(start_date, by = "hour", length.out = total_hours)
1733521486131:# Map simulation times to observation times
1733521486131:mapped_times <- vapply(expanded_times, function(sim_date) {
1733521486131:map_to_obs_date(sim_date, met)
1733521486140:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733525268984:print(paste0(obs_year, "-", month_day))
1733525283715:mapped_times
1733525324208:str(expanded_times)
1733525458073:# Function to map simulation date to observation date
1733525458074:map_to_obs_date <- function(sim_date, obs, hourly = TRUE) {
1733525458074:# Ensure sim_date is in POSIXct format (adjust if needed)
1733525458075:sim_date <- as.POSIXct(sim_date)
1733525458075:# Get simulation year and month/day
1733525458075:sim_year <- as.numeric(format(sim_date, "%Y"))
1733525458076:month_day <- format(sim_date, "%m-%d")
1733525458076:# Set time to "00:00:00" if hourly is FALSE, otherwise use the actual time from sim_date
1733525458076:time <- if (hourly) format(sim_date, "%H:%M:%S") else "00:00:00"
1733525458078:# Initialize observation year variable
1733525458078:obs_year <- sim_year
1733525458078:# Map simulation years (2000-2015) to observation years (2016-2021)
1733525458078:if (sim_date < as.POSIXct("2015-07-07")) {
1733525458079:if (sim_year >= 2000 && sim_year <= 2015) {
1733525458080:# Map 2000-2015 to 2016-2021 based on the modulo calculation
1733525458081:obs_year <- 2016 + ((sim_year - 2000) %% 6)  # Loop through 2016-2021 (6 years)
1733525458081:}
1733525458082:} else {
1733525458082:# After July 7, 2015, use actual observation years
1733525458082:obs_year <- sim_year
1733525458083:}
1733525458085:# Adjust leap year dates (e.g., February 29th)
1733525458085:if ((obs_year == 2016 || obs_year == 2020 || obs_year == 2024) && month_day == "02-29") {
1733525458086:# If the observation year is a leap year and it's February 29, change to February 28
1733525458086:month_day <- "02-28"
1733525458086:}
1733525458087:# Construct observation date in POSIXct format
1733525458087:obs_date_string <- paste0(obs_year, "-", month_day, " ", time)
1733525458087:obs_date <- as.POSIXct(obs_date_string, format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
1733525458087:# For non-hourly data (just dates), reset time to 00:00:00
1733525458088:if (!hourly) {
1733525458088:obs_date <- as.POSIXct(format(obs_date, "%Y-%m-%d"), tz = "UTC")
1733525458088:}
1733525458090:# Check if obs_date is in obs data and return; if not, return NA
1733525458090:if (!is.na(obs_date) && obs_date %in% obs$time) {
1733525458090:return(obs_date)
1733525458090:} else {
1733525458091:if (hourly) {
1733525458091:cat("No match for obs_date:", sim_date, "\n")
1733525458091:}
1733525458091:return(NA)
1733525458092:}
1733525458092:}
1733525463588:# Step 2: Adjust the met files
1733525463590:met_file <- if (scenario[i] == "baseline") {
1733525463590:paste0("sims/", scenario[i], "/inputs/met.csv")
1733525463591:} else {
1733525463592:paste0("sims/", scenario[i], "/inputs/met_", scenario[i], ".csv")
1733525463592:}
1733525467950:met <- read.csv(met_file) |>
1733525467950:dplyr::mutate(time = as.POSIXct(paste0(time, ":00"),
1733525467950:format = "%Y-%m-%d %H:%M:%S", tz = "UTC")) |>
1733525467951:dplyr::filter(time >= as.POSIXct("2015-07-08"))
1733525469504:# Generate the sequence of simulation dates
1733525469506:expanded_times <- seq(start_date, by = "hour", length.out = total_hours)
1733525474629:str(expanded_times)
1733525478099:# Map simulation times to observation times
1733525478102:mapped_times <- vapply(expanded_times, function(sim_date) {
1733525478105:map_to_obs_date(sim_date, met)
1733525478106:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733525650551:expanded_times
1733525659476:mapped_times <- as.POSIXct(mapped_times, format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
1733525676510:na.locf(mapped_times, na.rm = FALSE)
1733525680390:mapped_times
1733525688475:# Create the expanded met data frame
1733525688476:expanded_met <- data.frame(
1733525688476:time = expanded_times,
1733525688477:obs_time = mapped_times
1733525688478:)
1733525692533:View(expanded_met)
1733525777986:# Join with met based on obs_time to get corresponding observations
1733525777987:expanded_met <- merge(expanded_met, met, by.x = "obs_time",
1733525777987:by.y = "time", all.x = TRUE) |>
1733525777987:dplyr::select(-obs_time)|>
1733525777988:arrange(time)
1733525786215:library(dplyr)
1733525789757:# Join with met based on obs_time to get corresponding observations
1733525789757:expanded_met <- merge(expanded_met, met, by.x = "obs_time",
1733525789757:by.y = "time", all.x = TRUE) |>
1733525789757:dplyr::select(-obs_time)|>
1733525789758:arrange(time)
1733525793690:View(expanded_met)
1733525805031:write.csv(expanded_met, paste0("sims/spinup/",scenario[i],"/inputs/met.csv"),
1733525805033:row.names = FALSE)
1733525839096:inflow_file <-  "sims/baseline/inputs/BVR_inflow_2015_2022_allfractions_2poolsDOC_withch4_metInflow_0.65X_silica_0.2X_nitrate_0.4X_ammonium_1.9X_docr_1.7Xdoc.csv"
1733525846348:inflow <- read.csv(inflow_file) |>
1733525846350:dplyr::mutate(time = as.POSIXct(
1733525846351:paste(time,"00:00:00"),
1733525846351:format = "%Y-%m-%d %H:%M:%S", tz = "UTC"))
1733525847850:# Generate the sequence of simulation dates
1733525847851:expanded_times <- seq(as.Date(start_date), by = "day",
1733525847851:length.out = total_days)
1733525848899:# Map simulation times to observation times
1733525848900:mapped_days_inflow <- vapply(expanded_times, function(sim_date) {
1733525848900:map_to_obs_date(sim_date, inflow, hourly = FALSE)
1733525848900:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733525852221:mapped_days_inflow <- as.POSIXct(mapped_days_inflow, format = "%Y-%m-%d", tz = "UTC")
1733525852221:# Replace NA values with the previous valid datetime
1733525852221:mapped_days_inflow <- na.locf(mapped_days_inflow, na.rm = FALSE)
1733525858959:# Create the expanded inflow data frame
1733525858960:expanded_inflow <- data.frame(
1733525858960:time = expanded_times,
1733525858960:obs_time = mapped_days_inflow
1733525858961:)
1733525865101:# Join with met based on obs_time to get corresponding observations
1733525865101:expanded_inflow <- merge(expanded_inflow, inflow, by.x = "obs_time",
1733525865103:by.y = "time", all.x = TRUE) |>
1733525865103:dplyr::select(-obs_time) |>
1733525865104:arrange(time)
1733525866974:View(expanded_inflow)
1733525876121:write.csv(expanded_inflow, paste0("sims/spinup/",scenario[i],"/inputs/BVR_inflow_2015_2022_allfractions_2poolsDOC_withch4_metInflow_0.65X_silica_0.2X_nitrate_0.4X_ammonium_1.9X_docr_1.7Xdoc.csv"),
1733525876122:row.names = FALSE)
1733526462854:# Function to map simulation date to observation date
1733526462855:map_to_obs_date <- function(sim_date, obs, hourly = TRUE) {
1733526462855:# Ensure sim_date is in POSIXct format (adjust if needed)
1733526462855:sim_date <- as.POSIXct(sim_date)
1733526462856:# Get simulation year and month/day
1733526462856:sim_year <- as.numeric(format(sim_date, "%Y"))
1733526462856:month_day <- format(sim_date, "%m-%d")
1733526462856:# Set time to "00:00:00" if hourly is FALSE, otherwise use the actual time from sim_date
1733526462856:time <- if (hourly) format(sim_date, "%H:%M:%S") else "00:00:00"
1733526462857:# Initialize observation year variable
1733526462857:obs_year <- sim_year
1733526462857:# Map simulation years (2000-2015) to observation years (2016-2021)
1733526462857:if (sim_date < as.POSIXct("2015-07-08")) {
1733526462857:if (sim_year >= 2000 && sim_year <= 2015) {
1733526462858:# Map 2000-2015 to 2016-2021 based on the modulo calculation
1733526462858:obs_year <- 2016 + ((sim_year - 2000) %% 6)  # Loop through 2016-2021 (6 years)
1733526462858:}
1733526462858:} else {
1733526462858:# After July 7, 2015, use actual observation years
1733526462858:obs_year <- sim_year
1733526462859:}
1733526462859:# Adjust leap year dates (e.g., February 29th)
1733526462859:if ((obs_year == 2016 || obs_year == 2020 || obs_year == 2024) && month_day == "02-29") {
1733526462859:# If the observation year is a leap year and it's February 29, change to March 1
1733526462860:month_day <- "03-01"
1733526462860:}
1733526462860:# Construct observation date in POSIXct format
1733526462860:obs_date_string <- paste0(obs_year, "-", month_day, " ", time)
1733526462861:obs_date <- as.POSIXct(obs_date_string, format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
1733526462861:# For non-hourly data (just dates), reset time to 00:00:00
1733526462861:if (!hourly) {
1733526462861:obs_date <- as.POSIXct(format(obs_date, "%Y-%m-%d"), tz = "UTC")
1733526462862:}
1733526462862:# Check if obs_date is in obs data and return; if not, return NA
1733526462862:if (!is.na(obs_date) && obs_date %in% obs$time) {
1733526462862:return(obs_date)
1733526462863:} else {
1733526462863:if (hourly) {
1733526462863:cat("No match for obs_date:", sim_date, "\n")
1733526462864:}
1733526462865:return(NA)
1733526462865:}
1733526462866:}
1733526468730:scenario
1733526470810:i
1733526472599:# Step 2: Adjust the met files
1733526472600:met_file <- if (scenario[i] == "baseline") {
1733526472601:paste0("sims/", scenario[i], "/inputs/met.csv")
1733526472603:} else {
1733526472604:paste0("sims/", scenario[i], "/inputs/met_", scenario[i], ".csv")
1733526472608:}
1733526473104:met <- read.csv(met_file) |>
1733526473105:dplyr::mutate(time = as.POSIXct(paste0(time, ":00"),
1733526473105:format = "%Y-%m-%d %H:%M:%S", tz = "UTC")) |>
1733526473106:dplyr::filter(time >= as.POSIXct("2015-07-08"))
1733526474045:# Generate the sequence of simulation dates
1733526474045:expanded_times <- seq(start_date, by = "hour", length.out = total_hours)
1733526474958:# Map simulation times to observation times
1733526474958:mapped_times <- vapply(expanded_times, function(sim_date) {
1733526474959:map_to_obs_date(sim_date, met)
1733526474959:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733526609179:mapped_times <- as.POSIXct(mapped_times, format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
1733526610962:# Create the expanded met data frame
1733526610963:expanded_met <- data.frame(
1733526610963:time = expanded_times,
1733526610963:obs_time = mapped_times
1733526610963:)
1733526613078:# Join with met based on obs_time to get corresponding observations
1733526613079:expanded_met <- merge(expanded_met, met, by.x = "obs_time",
1733526613079:by.y = "time", all.x = TRUE) |>
1733526613079:dplyr::select(-obs_time)|>
1733526613079:arrange(time)
1733526614685:# Save met file
1733526614691:if(scenario[i]=="baseline"){
1733526614691:write.csv(expanded_met, paste0("sims/spinup/",scenario[i],"/inputs/met.csv"),
1733526614691:row.names = FALSE)
1733526614692:} else{
1733526614692:write.csv(expanded_met, paste0("sims/spinup/",scenario[i],"/inputs/met_",scenario[i],".csv"),
1733526614693:row.names = FALSE)
1733526614693:}
1733526619314:# Step 3: Adjust the inflow file similarly
1733526619314:inflow_file <- if (scenario[i] == "baseline") {
1733526619314:"sims/baseline/inputs/BVR_inflow_2015_2022_allfractions_2poolsDOC_withch4_metInflow_0.65X_silica_0.2X_nitrate_0.4X_ammonium_1.9X_docr_1.7Xdoc.csv"
1733526619314:} else {
1733526619315:paste0("sims/", scenario[i], "/inputs/inflow_", scenario[i], ".csv")
1733526619315:}
1733526619316:inflow <- read.csv(inflow_file) |>
1733526619316:dplyr::mutate(time = as.POSIXct(
1733526619316:paste(time,"00:00:00"),
1733526619316:format = "%Y-%m-%d %H:%M:%S", tz = "UTC"))
1733526619622:# Generate the sequence of simulation dates
1733526619623:expanded_times <- seq(as.Date(start_date), by = "day",
1733526619623:length.out = total_days)
1733526619624:# Map simulation times to observation times
1733526619624:mapped_days_inflow <- vapply(expanded_times, function(sim_date) {
1733526619624:map_to_obs_date(sim_date, inflow, hourly = FALSE)
1733526619624:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733526630455:mapped_days_inflow <- as.POSIXct(mapped_days_inflow, format = "%Y-%m-%d", tz = "UTC")
1733526635929:# Create the expanded inflow data frame
1733526635933:expanded_inflow <- data.frame(
1733526635934:time = expanded_times,
1733526635935:obs_time = mapped_days_inflow
1733526635937:)
1733526636456:# Join with met based on obs_time to get corresponding observations
1733526636457:expanded_inflow <- merge(expanded_inflow, inflow, by.x = "obs_time",
1733526636457:by.y = "time", all.x = TRUE) |>
1733526636457:dplyr::select(-obs_time) |>
1733526636458:arrange(time)
1733526636934:# Save inflow file
1733526636934:if(scenario[i]=="baseline"){
1733526636935:write.csv(expanded_inflow, paste0("sims/spinup/",scenario[i],"/inputs/BVR_inflow_2015_2022_allfractions_2poolsDOC_withch4_metInflow_0.65X_silica_0.2X_nitrate_0.4X_ammonium_1.9X_docr_1.7Xdoc.csv"),
1733526636935:row.names = FALSE)
1733526636935:} else{
1733526636936:write.csv(expanded_inflow, paste0("sims/spinup/",scenario[i],"/inputs/inflow_",scenario[i],".csv"),
1733526636936:row.names = FALSE)
1733526636936:}
1733526638054:# Step 4: Adjust the outflow file
1733526638055:outflow_file <- "sims/baseline/inputs/BVR_spillway_outflow_2015_2022_metInflow.csv"
1733527025439:#list of scenarios
1733527025439:scenario <- c("baseline","plus1","plus5","plus10")
1733527025893:for (i in 1:length(scenario)){
1733527025895:subdirName <- paste0("./sims/spinup/",scenario[i])
1733527025896:folder<-dir.create(subdirName)
1733527025899:file.copy(from = glm_files, to = subdirName, recursive = TRUE)
1733527025900:outputdirName <- paste0(subdirName,"/output")
1733527025901:output_folder<-dir.create(outputdirName)
1733527025901:}
1733527032492:# assign names to scenarios
1733527032493:scenario_folder_names <- c("plus1","plus5","plus10")
1733527033519:# add corresponding degrees C to met Temp_C column for each scenario
1733527033519:temp_increments <- c(1,5,10)
1733527040750:for (i in 1:length(scenario_folder_names)){
1733527040752:# get met data filepath and read in met data
1733527040752:met_filepath <- paste0("./sims/",scenario_folder_names[i],"/inputs/met.csv")
1733527040754:met <- read.csv(met_filepath)
1733527040756:# add temp increments
1733527040757:met$AirTemp <- met$AirTemp + temp_increments[i]
1733527040759:# write to file
1733527040760:new_met_filepath <- paste0("./sims/spinup/",scenario_folder_names[i],"/inputs/met_",scenario_folder_names[i],".csv")
1733527040760:write.csv(met, new_met_filepath, row.names = FALSE, quote = FALSE)
1733527040761:# get inflow data filepath and read in data
1733527040761:inflow_filepath <- paste0("./sims/",scenario_folder_names[i],
1733527040761:"/inputs/BVR_inflow_2015_2022_allfractions_2poolsDOC_withch4_metInflow_0.65X_silica_0.2X_nitrate_0.4X_ammonium_1.9X_docr_1.7Xdoc.csv")
1733527040761:inflow <- read.csv(inflow_filepath)
1733527040762:# calculate bvr inflow temp based on met air temp
1733527040762:# step 1: get daily avg met for entire sim period
1733527040762:met_sub <- met |> dplyr::select(time, AirTemp) |>
1733527040762:dplyr::mutate(time = as.Date(time)) |>
1733527040762:dplyr::group_by(time) |>
1733527040763:dplyr::summarise(mean_airtemp = mean(AirTemp)) |>
1733527040763:dplyr::filter(time<= "2022-05-04")
1733527040763:# step 3: calculate fcr water temp using: weir temp = (0.75 * air temp) + 2.4
1733527040764:fcr_inflow_temp <- (0.75 * met_sub$mean_airtemp) + 2.4
1733527040764:# step 4: calculate bvr inflow temp using: BVR temp = (1.5 * FCR temp) - 9.21
1733527040767:inflow$TEMP <- (1.5 * fcr_inflow_temp) - 9.21
1733527040768:# write to file
1733527040768:new_inflow_filepath <- paste0("./sims/spinup/",scenario_folder_names[i],
1733527040769:"/inputs/inflow_",scenario_folder_names[i],".csv")
1733527040769:write.csv(inflow, new_inflow_filepath, row.names = FALSE, quote = FALSE)
1733527040770:# set nml to use scenario met data
1733527040771:scenario_nml_file <- file.path(paste0("./sims/spinup/",scenario_folder_names[i],"/glm3.nml"))
1733527040771:scenario_nml <- glmtools::read_nml(nml_file = scenario_nml_file)
1733527040772:scenario_nml <- glmtools::set_nml(scenario_nml, arg_list =
1733527040772:list("meteo_fl" = paste0("inputs/met_",scenario_folder_names[i],".csv"),
1733527040772:"inflow_fl" = paste0("inputs/inflow_",scenario_folder_names[i],".csv")))
1733527040773:glmtools::write_nml(scenario_nml, file = scenario_nml_file)
1733527040773:}
1733527135408:# Set start and end dates
1733527135409:start_date <- as.POSIXct("2000-07-08 00:00:00", tz = "UTC")
1733527135789:end_date <- as.POSIXct("2022-05-04 00:00:00", tz = "UTC")
1733527135924:total_hours <- as.numeric(difftime(end_date, start_date, units = "hours")) + 1
1733527136214:total_days <- ceiling(as.numeric(difftime(end_date, start_date, units = "days")) + 1)
1733527137287:# Define the observation period for cycling
1733527137288:obs_start_year <- 2015
1733527137471:obs_end_year <- 2022
1733527137592:obs_years <- seq(obs_start_year, obs_end_year)
1733527138454:# Function to map simulation date to observation date
1733527138461:map_to_obs_date <- function(sim_date, obs, hourly = TRUE) {
1733527138461:# Ensure sim_date is in POSIXct format (adjust if needed)
1733527138462:sim_date <- as.POSIXct(sim_date)
1733527138463:# Get simulation year and month/day
1733527138464:sim_year <- as.numeric(format(sim_date, "%Y"))
1733527138465:month_day <- format(sim_date, "%m-%d")
1733527138466:# Set time to "00:00:00" if hourly is FALSE, otherwise use the actual time from sim_date
1733527138467:time <- if (hourly) format(sim_date, "%H:%M:%S") else "00:00:00"
1733527138467:# Initialize observation year variable
1733527138467:obs_year <- sim_year
1733527138468:# Map simulation years (2000-2015) to observation years (2016-2021)
1733527138468:if (sim_date < as.POSIXct("2015-07-08")) {
1733527138468:if (sim_year >= 2000 && sim_year <= 2015) {
1733527138468:# Map 2000-2015 to 2016-2021 based on the modulo calculation
1733527138469:obs_year <- 2016 + ((sim_year - 2000) %% 6)  # Loop through 2016-2021 (6 years)
1733527138469:}
1733527138469:} else {
1733527138470:# After July 7, 2015, use actual observation years
1733527138470:obs_year <- sim_year
1733527138470:}
1733527138471:# Adjust leap year dates (e.g., February 29th)
1733527138471:if ((obs_year == 2016 || obs_year == 2020 || obs_year == 2024) && month_day == "02-29") {
1733527138471:# If the observation year is a leap year and it's February 29, change to March 1
1733527138472:month_day <- "03-01"
1733527138472:}
1733527138472:# Construct observation date in POSIXct format
1733527138473:obs_date_string <- paste0(obs_year, "-", month_day, " ", time)
1733527138473:obs_date <- as.POSIXct(obs_date_string, format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
1733527138474:# For non-hourly data (just dates), reset time to 00:00:00
1733527138474:if (!hourly) {
1733527138475:obs_date <- as.POSIXct(format(obs_date, "%Y-%m-%d"), tz = "UTC")
1733527138476:}
1733527138477:# Check if obs_date is in obs data and return; if not, return NA
1733527138478:if (!is.na(obs_date) && obs_date %in% obs$time) {
1733527138483:return(obs_date)
1733527138484:} else {
1733527138484:if (hourly) {
1733527138484:cat("No match for obs_date:", sim_date, "\n")
1733527138484:}
1733527138485:return(NA)
1733527138485:}
1733527138485:}
1733527140702:# Iterate through each scenario
1733527140704:for (i in 1:length(scenario)) {
1733527140706:# Step 1: Set file paths and update start date in the .nml file
1733527140706:scenario_nml_file <- file.path(paste0("./sims/", scenario[i], "/glm3.nml"))
1733527140707:scenario_nml <- glmtools::read_nml(nml_file = scenario_nml_file)
1733527140708:scenario_nml <- glmtools::set_nml(scenario_nml, arg_name = "start",
1733527140710:arg_val = format(start_date, "%Y-%m-%d %H:%M:%S"))
1733527140710:glmtools::write_nml(scenario_nml, file = scenario_nml_file)
1733527140712:# Step 2: Adjust the met files
1733527140714:met_file <- if (scenario[i] == "baseline") {
1733527140715:paste0("sims/", scenario[i], "/inputs/met.csv")
1733527140715:} else {
1733527140716:paste0("sims/", scenario[i], "/inputs/met_", scenario[i], ".csv")
1733527140717:}
1733527140719:met <- read.csv(met_file) |>
1733527140720:dplyr::mutate(time = as.POSIXct(paste0(time, ":00"),
1733527140721:format = "%Y-%m-%d %H:%M:%S", tz = "UTC")) |>
1733527140722:dplyr::filter(time >= as.POSIXct("2015-07-08"))
1733527140722:# Generate the sequence of simulation dates
1733527140723:expanded_times <- seq(start_date, by = "hour", length.out = total_hours)
1733527140723:# Map simulation times to observation times
1733527140723:mapped_times <- vapply(expanded_times, function(sim_date) {
1733527140724:map_to_obs_date(sim_date, met)
1733527140724:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733527140725:mapped_times <- as.POSIXct(mapped_times, format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
1733527140727:# Create the expanded met data frame
1733527140728:expanded_met <- data.frame(
1733527140729:time = expanded_times,
1733527140730:obs_time = mapped_times
1733527140730:)
1733527140731:# Join with met based on obs_time to get corresponding observations
1733527140731:expanded_met <- merge(expanded_met, met, by.x = "obs_time",
1733527140732:by.y = "time", all.x = TRUE) |>
1733527140732:dplyr::select(-obs_time)|>
1733527140732:arrange(time)
1733527140733:# Save met file
1733527140733:if(scenario[i]=="baseline"){
1733527140736:write.csv(expanded_met, paste0("sims/spinup/",scenario[i],"/inputs/met.csv"),
1733527140736:row.names = FALSE)
1733527140737:} else{
1733527140737:write.csv(expanded_met, paste0("sims/spinup/",scenario[i],"/inputs/met_",scenario[i],".csv"),
1733527140737:row.names = FALSE)
1733527140737:}
1733527140738:# Step 3: Adjust the inflow file similarly
1733527140738:inflow_file <- if (scenario[i] == "baseline") {
1733527140739:"sims/baseline/inputs/BVR_inflow_2015_2022_allfractions_2poolsDOC_withch4_metInflow_0.65X_silica_0.2X_nitrate_0.4X_ammonium_1.9X_docr_1.7Xdoc.csv"
1733527140739:} else {
1733527140739:paste0("sims/", scenario[i], "/inputs/inflow_", scenario[i], ".csv")
1733527140740:}
1733527140740:inflow <- read.csv(inflow_file) |>
1733527140740:dplyr::mutate(time = as.POSIXct(
1733527140740:paste(time,"00:00:00"),
1733527140741:format = "%Y-%m-%d %H:%M:%S", tz = "UTC"))
1733527140741:# Generate the sequence of simulation dates
1733527140742:expanded_times <- seq(as.Date(start_date), by = "day",
1733527140742:length.out = total_days)
1733527140743:# Map simulation times to observation times
1733527140743:mapped_days_inflow <- vapply(expanded_times, function(sim_date) {
1733527140744:map_to_obs_date(sim_date, inflow, hourly = FALSE)
1733527140744:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733527140744:mapped_days_inflow <- as.POSIXct(mapped_days_inflow, format = "%Y-%m-%d", tz = "UTC")
1733527140745:# Create the expanded inflow data frame
1733527140745:expanded_inflow <- data.frame(
1733527140746:time = expanded_times,
1733527140746:obs_time = mapped_days_inflow
1733527140746:)
1733527140747:# Join with met based on obs_time to get corresponding observations
1733527140747:expanded_inflow <- merge(expanded_inflow, inflow, by.x = "obs_time",
1733527140747:by.y = "time", all.x = TRUE) |>
1733527140748:dplyr::select(-obs_time) |>
1733527140748:arrange(time)
1733527140748:# Save inflow file
1733527140749:if(scenario[i]=="baseline"){
1733527140749:write.csv(expanded_inflow, paste0("sims/spinup/",scenario[i],"/inputs/BVR_inflow_2015_2022_allfractions_2poolsDOC_withch4_metInflow_0.65X_silica_0.2X_nitrate_0.4X_ammonium_1.9X_docr_1.7Xdoc.csv"),
1733527140749:row.names = FALSE)
1733527140750:} else{
1733527140750:write.csv(expanded_inflow, paste0("sims/spinup/",scenario[i],"/inputs/inflow_",scenario[i],".csv"),
1733527140750:row.names = FALSE)
1733527140750:}
1733527140751:# Step 4: Adjust the outflow file
1733527140752:outflow_file <- "sims/baseline/inputs/BVR_spillway_outflow_2015_2022_metInflow.csv"
1733527140752:outflow <- read.csv(outflow_file) |>
1733527140753:dplyr::mutate(time = as.POSIXct(
1733527140753:paste(time,"00:00:00"),
1733527140753:format = "%Y-%m-%d %H:%M:%S", tz = "UTC"))
1733527140754:# Generate the sequence of simulation dates
1733527140754:expanded_times <- seq(as.Date(start_date), by = "day",
1733527140754:length.out = total_days)
1733527140755:# Map simulation times to observation times
1733527140755:mapped_days_outflow <- vapply(expanded_times, function(sim_date) {
1733527140756:map_to_obs_date(sim_date, outflow, hourly = FALSE)
1733527140756:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733527140756:mapped_days_outflow <- as.POSIXct(mapped_days_outflow,
1733527140757:format = "%Y-%m-%d", tz = "UTC")
1733527140757:# Replace NA values with the previous valid datetime
1733527140757:mapped_days_outflow <- na.locf(mapped_days_outflow, na.rm = FALSE)
1733527140758:# Create the expanded met data frame
1733527140758:expanded_outflow <- data.frame(
1733527140759:time = expanded_times,
1733527140759:obs_time = mapped_days_outflow
1733527140759:)
1733527140760:# Join with met based on obs_time to get corresponding observations
1733527140760:expanded_outflow <- merge(expanded_outflow, outflow, by.x = "obs_time",
1733527140760:by.y = "time", all.x = TRUE) |>
1733527140760:dplyr::select(-obs_time) |>
1733527140761:arrange(time)
1733527140761:# Save the file
1733527140761:write.csv(expanded_outflow, paste0("sims/spinup/",scenario[i],"/inputs/BVR_spillway_outflow_2015_2022_metInflow.csv"),
1733527140762:row.names = FALSE)
1733527140762:}
1733527340641:# create a folder for each scenarios and populate with sim files
1733527340642:glm_files = list.files("./sims/baseline", full.names = TRUE)[1:3]
1733527340954:#list of scenarios
1733527340954:scenario <- c("baseline","plus1","plus5","plus10")
1733527342011:for (i in 1:length(scenario)){
1733527342012:subdirName <- paste0("./sims/spinup/",scenario[i])
1733527342012:folder<-dir.create(subdirName)
1733527342013:file.copy(from = glm_files, to = subdirName, recursive = TRUE)
1733527342013:outputdirName <- paste0(subdirName,"/output")
1733527342013:output_folder<-dir.create(outputdirName)
1733527342014:}
1733527342882:# assign names to scenarios
1733527342883:scenario_folder_names <- c("plus1","plus5","plus10")
1733527343228:# add corresponding degrees C to met Temp_C column for each scenario
1733527343228:temp_increments <- c(1,5,10)
1733527343841:for (i in 1:length(scenario_folder_names)){
1733527343842:# get met data filepath and read in met data
1733527343843:met_filepath <- paste0("./sims/",scenario_folder_names[i],"/inputs/met.csv")
1733527343843:met <- read.csv(met_filepath)
1733527343844:# add temp increments
1733527343844:met$AirTemp <- met$AirTemp + temp_increments[i]
1733527343846:# write to file
1733527343846:new_met_filepath <- paste0("./sims/spinup/",scenario_folder_names[i],"/inputs/met_",scenario_folder_names[i],".csv")
1733527343847:write.csv(met, new_met_filepath, row.names = FALSE, quote = FALSE)
1733527343848:# get inflow data filepath and read in data
1733527343848:inflow_filepath <- paste0("./sims/",scenario_folder_names[i],
1733527343849:"/inputs/BVR_inflow_2015_2022_allfractions_2poolsDOC_withch4_metInflow_0.65X_silica_0.2X_nitrate_0.4X_ammonium_1.9X_docr_1.7Xdoc.csv")
1733527343849:inflow <- read.csv(inflow_filepath)
1733527343850:# calculate bvr inflow temp based on met air temp
1733527343850:# step 1: get daily avg met for entire sim period
1733527343850:met_sub <- met |> dplyr::select(time, AirTemp) |>
1733527343853:dplyr::mutate(time = as.Date(time)) |>
1733527343854:dplyr::group_by(time) |>
1733527343855:dplyr::summarise(mean_airtemp = mean(AirTemp)) |>
1733527343855:dplyr::filter(time<= "2022-05-04")
1733527343857:# step 3: calculate fcr water temp using: weir temp = (0.75 * air temp) + 2.4
1733527343857:fcr_inflow_temp <- (0.75 * met_sub$mean_airtemp) + 2.4
1733527343858:# step 4: calculate bvr inflow temp using: BVR temp = (1.5 * FCR temp) - 9.21
1733527343859:inflow$TEMP <- (1.5 * fcr_inflow_temp) - 9.21
1733527343860:# write to file
1733527343861:new_inflow_filepath <- paste0("./sims/spinup/",scenario_folder_names[i],
1733527343861:"/inputs/inflow_",scenario_folder_names[i],".csv")
1733527343862:write.csv(inflow, new_inflow_filepath, row.names = FALSE, quote = FALSE)
1733527343862:# set nml to use scenario met data
1733527343862:scenario_nml_file <- file.path(paste0("./sims/spinup/",scenario_folder_names[i],"/glm3.nml"))
1733527343863:scenario_nml <- glmtools::read_nml(nml_file = scenario_nml_file)
1733527343863:scenario_nml <- glmtools::set_nml(scenario_nml, arg_list =
1733527343863:list("meteo_fl" = paste0("inputs/met_",scenario_folder_names[i],".csv"),
1733527343864:"inflow_fl" = paste0("inputs/inflow_",scenario_folder_names[i],".csv")))
1733527343864:glmtools::write_nml(scenario_nml, file = scenario_nml_file)
1733527343864:}
1733527350072:# Set start and end dates
1733527350072:start_date <- as.POSIXct("2000-07-08 00:00:00", tz = "UTC")
1733527350073:end_date <- as.POSIXct("2022-05-04 00:00:00", tz = "UTC")
1733527350073:total_hours <- as.numeric(difftime(end_date, start_date, units = "hours")) + 1
1733527350074:total_days <- ceiling(as.numeric(difftime(end_date, start_date, units = "days")) + 1)
1733527350074:# Define the observation period for cycling
1733527350074:obs_start_year <- 2015
1733527350075:obs_end_year <- 2022
1733527350075:obs_years <- seq(obs_start_year, obs_end_year)
1733527350075:# Function to map simulation date to observation date
1733527350076:map_to_obs_date <- function(sim_date, obs, hourly = TRUE) {
1733527350076:# Ensure sim_date is in POSIXct format (adjust if needed)
1733527350076:sim_date <- as.POSIXct(sim_date)
1733527350076:# Get simulation year and month/day
1733527350076:sim_year <- as.numeric(format(sim_date, "%Y"))
1733527350076:month_day <- format(sim_date, "%m-%d")
1733527350077:# Set time to "00:00:00" if hourly is FALSE, otherwise use the actual time from sim_date
1733527350077:time <- if (hourly) format(sim_date, "%H:%M:%S") else "00:00:00"
1733527350077:# Initialize observation year variable
1733527350078:obs_year <- sim_year
1733527350078:# Map simulation years (2000-2015) to observation years (2016-2021)
1733527350078:if (sim_date < as.POSIXct("2015-07-08")) {
1733527350078:if (sim_year >= 2000 && sim_year <= 2015) {
1733527350078:# Map 2000-2015 to 2016-2021 based on the modulo calculation
1733527350078:obs_year <- 2016 + ((sim_year - 2000) %% 6)  # Loop through 2016-2021 (6 years)
1733527350079:}
1733527350079:} else {
1733527350079:# After July 7, 2015, use actual observation years
1733527350079:obs_year <- sim_year
1733527350079:}
1733527350079:# Adjust leap year dates (e.g., February 29th)
1733527350080:if ((obs_year == 2016 || obs_year == 2020 || obs_year == 2024) && month_day == "02-29") {
1733527350080:# If the observation year is a leap year and it's February 29, change to March 1
1733527350080:month_day <- "03-01"
1733527350080:}
1733527350080:# Construct observation date in POSIXct format
1733527350081:obs_date_string <- paste0(obs_year, "-", month_day, " ", time)
1733527350081:obs_date <- as.POSIXct(obs_date_string, format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
1733527350081:# For non-hourly data (just dates), reset time to 00:00:00
1733527350081:if (!hourly) {
1733527350081:obs_date <- as.POSIXct(format(obs_date, "%Y-%m-%d"), tz = "UTC")
1733527350081:}
1733527350082:# Check if obs_date is in obs data and return; if not, return NA
1733527350082:if (!is.na(obs_date) && obs_date %in% obs$time) {
1733527350083:return(obs_date)
1733527350083:} else {
1733527350083:if (hourly) {
1733527350083:cat("No match for obs_date:", sim_date, "\n")
1733527350083:}
1733527350083:return(NA)
1733527350083:}
1733527350084:}
1733527350084:# Iterate through each scenario
1733527350085:for (i in 1:length(scenario)) {
1733527350085:# Step 1: Set file paths and update start date in the .nml file
1733527350085:scenario_nml_file <- file.path(paste0("./sims/", scenario[i], "/glm3.nml"))
1733527350085:scenario_nml <- glmtools::read_nml(nml_file = scenario_nml_file)
1733527350085:scenario_nml <- glmtools::set_nml(scenario_nml, arg_name = "start",
1733527350085:arg_val = format(start_date, "%Y-%m-%d %H:%M:%S"))
1733527350086:glmtools::write_nml(scenario_nml, file = scenario_nml_file)
1733527350086:# Step 2: Adjust the met files
1733527350086:met_file <- if (scenario[i] == "baseline") {
1733527350086:paste0("sims/", scenario[i], "/inputs/met.csv")
1733527350086:} else {
1733527350086:paste0("sims/", scenario[i], "/inputs/met_", scenario[i], ".csv")
1733527350087:}
1733527350087:met <- read.csv(met_file) |>
1733527350087:dplyr::mutate(time = as.POSIXct(paste0(time, ":00"),
1733527350087:format = "%Y-%m-%d %H:%M:%S", tz = "UTC")) |>
1733527350087:dplyr::filter(time >= as.POSIXct("2015-07-08"))
1733527350088:# Generate the sequence of simulation dates
1733527350088:expanded_times <- seq(start_date, by = "hour", length.out = total_hours)
1733527350088:# Map simulation times to observation times
1733527350088:mapped_times <- vapply(expanded_times, function(sim_date) {
1733527350089:map_to_obs_date(sim_date, met)
1733527350089:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733527350089:mapped_times <- as.POSIXct(mapped_times, format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
1733527350090:# Create the expanded met data frame
1733527350090:expanded_met <- data.frame(
1733527350090:time = expanded_times,
1733527350091:obs_time = mapped_times
1733527350091:)
1733527350092:# Join with met based on obs_time to get corresponding observations
1733527350093:expanded_met <- merge(expanded_met, met, by.x = "obs_time",
1733527350093:by.y = "time", all.x = TRUE) |>
1733527350093:dplyr::select(-obs_time)|>
1733527350094:arrange(time)
1733527350094:# Save met file
1733527350094:if(scenario[i]=="baseline"){
1733527350095:write.csv(expanded_met, paste0("sims/spinup/",scenario[i],"/inputs/met.csv"),
1733527350095:row.names = FALSE)
1733527350095:} else{
1733527350096:write.csv(expanded_met, paste0("sims/spinup/",scenario[i],"/inputs/met_",scenario[i],".csv"),
1733527350096:row.names = FALSE)
1733527350096:}
1733527350097:# Step 3: Adjust the inflow file similarly
1733527350097:inflow_file <- if (scenario[i] == "baseline") {
1733527350098:"sims/baseline/inputs/BVR_inflow_2015_2022_allfractions_2poolsDOC_withch4_metInflow_0.65X_silica_0.2X_nitrate_0.4X_ammonium_1.9X_docr_1.7Xdoc.csv"
1733527350098:} else {
1733527350098:paste0("sims/", scenario[i], "/inputs/inflow_", scenario[i], ".csv")
1733527350099:}
1733527350099:inflow <- read.csv(inflow_file) |>
1733527350100:dplyr::mutate(time = as.POSIXct(
1733527350100:paste(time,"00:00:00"),
1733527350100:format = "%Y-%m-%d %H:%M:%S", tz = "UTC"))
1733527350101:# Generate the sequence of simulation dates
1733527350101:expanded_times <- seq(as.Date(start_date), by = "day",
1733527350101:length.out = total_days)
1733527350102:# Map simulation times to observation times
1733527350102:mapped_days_inflow <- vapply(expanded_times, function(sim_date) {
1733527350102:map_to_obs_date(sim_date, inflow, hourly = FALSE)
1733527350103:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733527350104:mapped_days_inflow <- as.POSIXct(mapped_days_inflow, format = "%Y-%m-%d", tz = "UTC")
1733527350104:# Create the expanded inflow data frame
1733527350105:expanded_inflow <- data.frame(
1733527350105:time = expanded_times,
1733527350105:obs_time = mapped_days_inflow
1733527350105:)
1733527350106:# Join with met based on obs_time to get corresponding observations
1733527350106:expanded_inflow <- merge(expanded_inflow, inflow, by.x = "obs_time",
1733527350106:by.y = "time", all.x = TRUE) |>
1733527350106:dplyr::select(-obs_time) |>
1733527350107:arrange(time)
1733527350107:# Save inflow file
1733527350107:if(scenario[i]=="baseline"){
1733527350107:write.csv(expanded_inflow, paste0("sims/spinup/",scenario[i],"/inputs/BVR_inflow_2015_2022_allfractions_2poolsDOC_withch4_metInflow_0.65X_silica_0.2X_nitrate_0.4X_ammonium_1.9X_docr_1.7Xdoc.csv"),
1733527350108:row.names = FALSE)
1733527350108:} else{
1733527350108:write.csv(expanded_inflow, paste0("sims/spinup/",scenario[i],"/inputs/inflow_",scenario[i],".csv"),
1733527350108:row.names = FALSE)
1733527350109:}
1733527350109:# Step 4: Adjust the outflow file
1733527350110:outflow_file <- "sims/baseline/inputs/BVR_spillway_outflow_2015_2022_metInflow.csv"
1733527350110:outflow <- read.csv(outflow_file) |>
1733527350112:dplyr::mutate(time = as.POSIXct(
1733527350112:paste(time,"00:00:00"),
1733527350112:format = "%Y-%m-%d %H:%M:%S", tz = "UTC"))
1733527350113:# Generate the sequence of simulation dates
1733527350113:expanded_times <- seq(as.Date(start_date), by = "day",
1733527350113:length.out = total_days)
1733527350114:# Map simulation times to observation times
1733527350114:mapped_days_outflow <- vapply(expanded_times, function(sim_date) {
1733527350115:map_to_obs_date(sim_date, outflow, hourly = FALSE)
1733527350115:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733527350115:mapped_days_outflow <- as.POSIXct(mapped_days_outflow,
1733527350116:format = "%Y-%m-%d", tz = "UTC")
1733527350116:# Create the expanded met data frame
1733527350116:expanded_outflow <- data.frame(
1733527350117:time = expanded_times,
1733527350117:obs_time = mapped_days_outflow
1733527350117:)
1733527350118:# Join with met based on obs_time to get corresponding observations
1733527350118:expanded_outflow <- merge(expanded_outflow, outflow, by.x = "obs_time",
1733527350118:by.y = "time", all.x = TRUE) |>
1733527350119:dplyr::select(-obs_time) |>
1733527350119:arrange(time)
1733527350120:# Save the file
1733527350120:write.csv(expanded_outflow, paste0("sims/spinup/",scenario[i],"/inputs/BVR_spillway_outflow_2015_2022_metInflow.csv"),
1733527350120:row.names = FALSE)
1733527350120:}
1733528026509:#-------------------------------------------------------------------------#
1733528026510:#quick plots of inflow temp to make sure above code is doing what I want it to
1733528026510:inflow_baseline <- read.csv("sims/spinup/baseline/inputs/BVR_inflow_2015_2022_allfractions_2poolsDOC_withch4_metInflow_0.65X_silica_0.2X_nitrate_0.4X_ammonium_1.9X_docr_1.7Xdoc.csv")
1733528026963:inflow_plus1 <- read.csv("sims/spinup/plus1/inputs/inflow_plus1.csv")
1733528027223:inflow_plus5 <- read.csv("sims/spinup/plus5/inputs/inflow_plus5.csv")
1733528028167:inflow_plus10 <- read.csv("sims/spinup/plus10/inputs/inflow_plus10.csv")
1733528029695:plot(as.Date(inflow_baseline$time), inflow_baseline$TEMP, ylim = c(-15,39),
1733528029696:col = "#00603d", type="l")
1733528031307:points(as.Date(inflow_plus1$time), inflow_plus1$TEMP,
1733528031308:col = "#c6a000", type="l")
1733528032300:points(as.Date(inflow_plus5$time), inflow_plus5$TEMP,
1733528032301:col = "#c85b00", type="l")
1733528033197:points(as.Date(inflow_plus10$time), inflow_plus10$TEMP,
1733528033198:col = "#680000", type="l")
1733528034134:legend("bottom", legend=c("baseline", "plus1C","plus5C","plus10C"),
1733528034135:col=c("#00603d","#c6a000","#c85b00","#680000"),
1733528034136:lty=1, cex=0.8, bty='n', horiz=T)
1733528035071:max(inflow_baseline$TEMP) # 29.8 (but mean is lower so okay I think)
1733528040235:View(inflow_baseline)
1733528164616:?na.locf
1733528168954:??na.locf
1733528273654:max(met_baseline$mean_airtemp) # 28.5
1733528276896:#now read in met
1733528276896:met_baseline <- read.csv("sims/spinup/baseline/inputs/met.csv") |>
1733528276896:dplyr::select(time, AirTemp) |>
1733528276897:dplyr::mutate(time = as.Date(time)) |>
1733528276897:dplyr::group_by(time) |>
1733528276897:dplyr::summarise(mean_airtemp = mean(AirTemp)) |>
1733528276898:dplyr::filter(time<= "2022-05-04")
1733528281448:max(met_baseline$mean_airtemp) # 28.5
1733528285506:View(met_baseline)
1733528381020:View(expanded_outflow)
1733528551326:View(expanded_met)
1733528741472:# Join with met based on obs_time to get corresponding observations
1733528741472:expanded_met <- merge(expanded_met, met, by.x = "obs_time",
1733528741473:by.y = "time", all.x = TRUE) |>
1733528741473:dplyr::select(-obs_time)|>
1733528741474:arrange(time) |>
1733528741475:group_by(Date = as.Date(time)) |>
1733528741475:mutate(across(everything(), ~ ifelse(is.na(.), lag(., order_by = time), .))) |>
1733528741476:ungroup()
1733528787127:colnames(met)
1733528791906:colnames(expanded_met)
1733528867341:# Join with met based on obs_time to get corresponding observations
1733528867342:expanded_met <- merge(expanded_met, met, by ="time", all.x = TRUE) |>
1733528867342:dplyr::select(-obs_time) |>
1733528867342:arrange(time) |>
1733528867343:group_by(Date = as.Date(time)) |>
1733528867343:mutate(across(everything(), ~ ifelse(is.na(.), lag(., order_by = time), .))) |>
1733528867343:ungroup()
1733528877003:# Join with met based on obs_time to get corresponding observations
1733528877004:expanded_met <- merge(expanded_met, met, by ="time", all.x = TRUE) |>
1733528877004:arrange(time) |>
1733528877004:group_by(Date = as.Date(time)) |>
1733528877005:mutate(across(everything(), ~ ifelse(is.na(.), lag(., order_by = time), .))) |>
1733528877005:ungroup()
1733528904727:View(expanded_met)
1733528926879:View(expanded_met)
1733528933247:# Create the expanded met data frame
1733528933250:expanded_met <- data.frame(
1733528933253:time = expanded_times,
1733528933253:obs_time = mapped_times
1733528933253:)
1733528950240:# Generate the sequence of simulation dates
1733528950241:expanded_times <- seq(start_date, by = "hour", length.out = total_hours)
1733528951596:# Map simulation times to observation times
1733528951597:mapped_times <- vapply(expanded_times, function(sim_date) {
1733528951597:map_to_obs_date(sim_date, met)
1733528951597:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733529161120:mapped_times <- as.POSIXct(mapped_times, format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
1733529162247:# Create the expanded met data frame
1733529162247:expanded_met <- data.frame(
1733529162248:time = expanded_times,
1733529162249:obs_time = mapped_times
1733529162249:)
1733529163990:# Join with met based on obs_time to get corresponding observations
1733529163991:expanded_met <- merge(expanded_met, met, by.x = "obs_time",
1733529163992:by.y = "time", all.x = TRUE) |>
1733529163992:dplyr::select(-obs_time)|>
1733529163993:arrange(time) |>
1733529163993:group_by(Date = as.Date(time)) |>
1733529163994:mutate(across(everything(), ~ ifelse(is.na(.), lag(., order_by = time), .))) |>
1733529163994:ungroup()
1733529168072:View(expanded_met)
1733529188564:mapped_times
1733529193348:# Create the expanded met data frame
1733529193354:expanded_met <- data.frame(
1733529193355:time = expanded_times,
1733529193356:obs_time = mapped_times
1733529193356:)
1733529199004:View(expanded_met)
1733529210944:View(expanded_met)
1733529216131:View(expanded_met)
1733529224148:View(met)
1733529237761:str(expanded_met$obs_time)
1733529244042:str(met$time)
1733529297346:# Join with met based on obs_time to get corresponding observations
1733529297346:expanded_met <- merge(expanded_met, met, by.x = "obs_time",
1733529297353:by.y = "time", all.x = TRUE) |>
1733529297353:dplyr::select(-obs_time)|>
1733529297353:arrange(time) |>
1733529297354:group_by(Date = as.Date(time)) |>
1733529297354:mutate(across(everything(), ~ ifelse(is.na(.), lag(., order_by = time), .))) |>
1733529297355:ungroup()
1733529308662:View(expanded_met)
1733529367011:# Create the expanded met data frame
1733529367011:expanded_met <- data.frame(
1733529367012:time = expanded_times,
1733529367015:obs_time = mapped_times
1733529367015:)
1733529369750:# Join with met based on obs_time to get corresponding observations
1733529369751:expanded_met <- merge(expanded_met, met, by.x = "obs_time",
1733529369751:by.y = "time", all.x = TRUE) |>
1733529369752:dplyr::select(-obs_time) |>
1733529369752:arrange(time) |>
1733529369753:group_by(Date = as.Date(time)) |>
1733529369753:mutate(across(where(~ !inherits(., "POSIXct")),
1733529369754:~ ifelse(is.na(.), lag(., order_by = time), .))) |>
1733529369754:ungroup()
1733529374905:View(expanded_met)
1733529658374:# Create the expanded met data frame
1733529658377:expanded_met <- data.frame(
1733529658377:time = expanded_times,
1733529658378:obs_time = mapped_times
1733529658385:)
1733529660073:# Join with met based on obs_time to get corresponding observations
1733529660073:expanded_met <- merge(expanded_met, met, by.x = "obs_time",
1733529660073:by.y = "time", all.x = TRUE) |>
1733529660073:dplyr::select(-obs_time) |>
1733529660074:arrange(time) |>
1733529660074:mutate(
1733529660074:# Check if DateTime matches a specific date and fill missing values from the previous day
1733529660074:across(everything(),
1733529660074:~ ifelse(as.Date(time) == as.Date("2008-02-29") & is.na(.),
1733529660074:lag(., order_by = time), .))
1733529660074:) |>
1733529660074:ungroup()
1733529693222:View(expanded_met)
1733529813666:# Create the expanded met data frame
1733529813667:expanded_met <- data.frame(
1733529813667:time = expanded_times,
1733529813668:obs_time = mapped_times
1733529813668:)
1733529815181:# Join with met based on obs_time to get corresponding observations
1733529815182:expanded_met <- expanded_met %>%
1733529815182:arrange(time) %>%
1733529815184:mutate(
1733529815186:# For the rows corresponding to the specific date, replace NAs with values from the previous day
1733529815187:across(everything(), ~ ifelse(as.Date(time) == as.Date("2008-02-29") & is.na(.),
1733529815187:lag(., order_by = time), .))
1733529815189:) %>%
1733529815190:ungroup()
1733529917100:# Create the expanded met data frame
1733529917102:expanded_met <- data.frame(
1733529917105:time = expanded_times,
1733529917107:obs_time = mapped_times
1733529917108:)
1733529919585:t <- expanded_met %>%
1733529919586:arrange(time) %>%
1733529919586:mutate(
1733529919587:# Replace NAs for the specific date with values from the previous row (lagging)
1733529919587:across(everything(), ~ ifelse(is.na(.), lag(., order_by = time), .))
1733529919587:) %>%
1733529919588:ungroup()
1733529920935:View(t)
1733529975305:View(expanded_met)
1733530070143:t <- merge(expanded_met, met, by.x = "obs_time",
1733530070143:by.y = "time", all.x = TRUE) |>
1733530070144:dplyr::select(-obs_time) |>
1733530070145:arrange(time) %>%
1733530070145:group_by(Date = as.Date(time)) %>%
1733530070146:mutate(across(everything(), ~ ifelse(is.na(.), zoo::na.locf(., na.rm = FALSE), .))) %>%
1733530070147:ungroup()
1733530074003:View(t)
1733530099275:t <- merge(expanded_met, met, by.x = "obs_time",
1733530099275:by.y = "time", all.x = TRUE) |>
1733530099275:dplyr::select(-obs_time) |>
1733530099276:arrange(time) %>%
1733530099276:group_by(Date = as.Date(time)) %>%
1733530099276:mutate(
1733530099276:across(everything(),
1733530099276:~ ifelse(as.Date(time) == "2008-02-29" & is.na(.), na.locf(., na.rm = FALSE), .))
1733530099277:)
1733530106819:t <- merge(expanded_met, met, by.x = "obs_time",
1733530106820:by.y = "time", all.x = TRUE) |>
1733530106821:dplyr::select(-obs_time) |>
1733530106822:arrange(time) %>%
1733530106822:group_by(Date = as.Date(time)) %>%
1733530106823:mutate(
1733530106823:across(everything(),
1733530106824:~ ifelse(as.Date(time) == "2008-02-29" & is.na(.), zoo::na.locf(., na.rm = FALSE), .))
1733530106824:)
1733530114725:View(t)
1733530184051:t <- merge(expanded_met, met, by.x = "obs_time",
1733530184051:by.y = "time", all.x = TRUE) |>
1733530184052:dplyr::select(-obs_time) |>
1733530184053:arrange(time) %>%
1733530184053:group_by(Date = as.Date(time)) %>%
1733530184054:mutate(across(everything(),
1733530184054:~ ifelse(as.Date(time) == "2008-02-29" & is.na(.),
1733530184055:na.locf(., na.rm = FALSE), .))) %>%
1733530184056:ungroup()
1733530191776:t <- merge(expanded_met, met, by.x = "obs_time",
1733530191777:by.y = "time", all.x = TRUE) |>
1733530191777:dplyr::select(-obs_time) |>
1733530191777:arrange(time) %>%
1733530191778:group_by(Date = as.Date(time)) %>%
1733530191779:mutate(across(everything(),
1733530191783:~ ifelse(as.Date(time) == "2008-02-29" & is.na(.),
1733530191786:zoo::na.locf(., na.rm = FALSE), .))) %>%
1733530191788:ungroup()
1733530201755:View(t)
1733530205479:View(expanded_met)
1733530208663:View(expanded_met)
1733530212918:View(met)
1733530230828:t <- merge(expanded_met, met, by.x = "obs_time",
1733530230828:by.y = "time", all.x = TRUE) |>
1733530230828:dplyr::select(-obs_time) |>
1733530230829:arrange(time) %>%
1733530230829:group_by(Date = as.Date(time)) %>%
1733530230829:mutate(across(everything(),
1733530230829:~ ifelse(as.Date(time) == "2008-02-29" & is.na(.),
1733530230830:zoo::na.locf(., na.rm = FALSE), .))) %>%
1733530230830:ungroup() %>%
1733530230830:mutate(time = as.POSIXct(time, origin = "1970-01-01", tz = "UTC"))
1733530242342:View(t)
1733530432628:t <- merge(expanded_met, met, by.x = "obs_time",
1733530432628:by.y = "time", all.x = TRUE) |>
1733530432629:dplyr::select(-obs_time) |>
1733530432629:arrange(time) %>%
1733530432629:group_by(Date = as.Date(time)) |>
1733530432630:mutate(
1733530432631:# Check if the row is on the missing day (e.g., 2008-02-29)
1733530432632:across(everything(), ~ ifelse(as.Date(time) == "2008-02-29" & is.na(.),
1733530432632:lag(., order_by = time), .))
1733530432633:) |>
1733530432633:ungroup()
1733530445470:head(expanded_met_filled)
1733530450546:head(t)
1733530471481:t <- merge(expanded_met, met, by.x = "obs_time",
1733530471481:by.y = "time", all.x = TRUE) |>
1733530471482:dplyr::select(-obs_time) |>
1733530471482:arrange(time) %>%
1733530471483:group_by(Date = as.Date(time)) |>
1733530471483:mutate(
1733530471484:# Check if the row is on the missing day (e.g., 2008-02-29)
1733530471485:across(everything(), ~ ifelse(as.Date(time) == "2008-02-29" & is.na(.),
1733530471485:lag(., order_by = time), .))
1733530471486:) |>
1733530471486:ungroup() |>
1733530471487:mutate(time = as.POSIXct(time, origin = "1970-01-01", tz = "UTC"))
1733530478012:View(t)
1733530569239:t[as.Date(t$time) %in% 2008-02-29,]
1733530720593:t <- merge(expanded_met, met, by.x = "obs_time",
1733530720594:by.y = "time", all.x = TRUE) |>
1733530720595:dplyr::select(-obs_time) |>
1733530720596:arrange(time) %>%
1733530720596:mutate(AirTemp = ifelse(as.Date(time) %in% "2008-02-29",
1733530720596:AirTemp[as.Date(time) %in% "2008-02-28"]))
1733530741063:t <- merge(expanded_met, met, by.x = "obs_time",
1733530741065:by.y = "time", all.x = TRUE) |>
1733530741066:dplyr::select(-obs_time) |>
1733530741066:arrange(time) %>%
1733530741068:mutate(
1733530741069:AirTemp = ifelse(as.Date(time) == "2008-02-29",
1733530741072:lag(AirTemp),  # Use the previous day's value
1733530741073:AirTemp)
1733530741074:)
1733530807975:t <- merge(expanded_met, met, by.x = "obs_time",
1733530807976:by.y = "time", all.x = TRUE) |>
1733530807976:dplyr::select(-obs_time) |>
1733530807976:arrange(time) %>%
1733530807978:mutate(
1733530807979:# Apply the lag for all columns when the date is February 29, 2008
1733530807980:across(where(is.numeric),
1733530807980:~ ifelse(as.Date(time) == "2008-02-29", lag(.), .))
1733530807981:)
1733530859804:t[t$tim %in% "2008-02-29 00:00:00",]
1733530877550:t[t$tim %in% as.POSIXct("2008-02-29 00:00:00"),]
1733530891851:t[t$tim %in% as.POSIXct("2008-02-28 00:00:00"),]
1733530898757:t[t$tim %in% as.POSIXct("2008-02-28 23:00:00"),]
1733530949941:t <- merge(expanded_met, met, by.x = "obs_time",
1733530949941:by.y = "time", all.x = TRUE) |>
1733530949942:dplyr::select(-obs_time) |>
1733530949942:arrange(time) %>%
1733530949942:mutate(
1733530949942:# Only apply to the specific date (Feb 29, 2008)
1733530949942:across(where(is.numeric),
1733530949943:~ ifelse(as.Date(time) == "2008-02-29",
1733530949943:na.locf(.), .))
1733530949943:)
1733530957111:t <- merge(expanded_met, met, by.x = "obs_time",
1733530957114:by.y = "time", all.x = TRUE) |>
1733530957114:dplyr::select(-obs_time) |>
1733530957114:arrange(time) %>%
1733530957118:mutate(
1733530957121:# Only apply to the specific date (Feb 29, 2008)
1733530957125:across(where(is.numeric),
1733530957126:~ ifelse(as.Date(time) == "2008-02-29",
1733530957127:zoo::na.locf(.), .))
1733530957128:)
1733531070671:t <- merge(expanded_met, met, by.x = "obs_time",
1733531070671:by.y = "time", all.x = TRUE) |>
1733531070672:dplyr::select(-obs_time) |>
1733531070672:arrange(time) %>%
1733531070672:mutate(
1733531070672:# Replace NAs for Feb 29, 2008 with the previous day's values
1733531070673:across(where(is.numeric),
1733531070673:~ ifelse(as.Date(time) == "2008-02-29" & is.na(.),
1733531070682:lag(., order_by = time), .))
1733531070683:)
1733531073957:View(t)
1733531138056:t <- merge(expanded_met, met, by.x = "obs_time",
1733531138057:by.y = "time", all.x = TRUE) |>
1733531138057:dplyr::select(-obs_time) |>
1733531138057:arrange(time) %>%
1733531138057:mutate(
1733531138058:# Replace missing values for Feb 29, 2008 with the values from Feb 28, 2008
1733531138058:across(where(is.numeric),
1733531138059:~ ifelse(as.Date(time) == "2008-02-29" & is.na(.),
1733531138060:filter(., as.Date(time) == "2008-02-28") %>% pull(.), .))
1733531138060:)
1733531181526:t <- merge(expanded_met, met, by.x = "obs_time",
1733531181532:by.y = "time", all.x = TRUE) |>
1733531181533:dplyr::select(-obs_time) |>
1733531181534:arrange(time) %>%
1733531181535:mutate(
1733531181537:# For missing values on 2008-02-29, replace them with values from 2008-02-28
1733531181538:AirTemp = ifelse(as.Date(time) == "2008-02-29" & is.na(AirTemp),
1733531181539:AirTemp[which(as.Date(time) == "2008-02-28")],
1733531181540:AirTemp)
1733531181541:)
1733531361482:#list of scenarios
1733531361482:scenario <- c("baseline","plus1","plus5","plus10")
1733531361720:for (i in 1:length(scenario)){
1733531361721:subdirName <- paste0("./sims/spinup/",scenario[i])
1733531361721:folder<-dir.create(subdirName)
1733531361721:file.copy(from = glm_files, to = subdirName, recursive = TRUE)
1733531361722:outputdirName <- paste0(subdirName,"/output")
1733531361722:output_folder<-dir.create(outputdirName)
1733531361722:}
1733531362842:# assign names to scenarios
1733531362843:scenario_folder_names <- c("plus1","plus5","plus10")
1733531363059:# add corresponding degrees C to met Temp_C column for each scenario
1733531363060:temp_increments <- c(1,5,10)
1733531363845:for (i in 1:length(scenario_folder_names)){
1733531363846:# get met data filepath and read in met data
1733531363847:met_filepath <- paste0("./sims/",scenario_folder_names[i],"/inputs/met.csv")
1733531363848:met <- read.csv(met_filepath)
1733531363849:# add temp increments
1733531363849:met$AirTemp <- met$AirTemp + temp_increments[i]
1733531363850:# write to file
1733531363851:new_met_filepath <- paste0("./sims/spinup/",scenario_folder_names[i],"/inputs/met_",scenario_folder_names[i],".csv")
1733531363851:write.csv(met, new_met_filepath, row.names = FALSE, quote = FALSE)
1733531363852:# get inflow data filepath and read in data
1733531363852:inflow_filepath <- paste0("./sims/",scenario_folder_names[i],
1733531363853:"/inputs/BVR_inflow_2015_2022_allfractions_2poolsDOC_withch4_metInflow_0.65X_silica_0.2X_nitrate_0.4X_ammonium_1.9X_docr_1.7Xdoc.csv")
1733531363854:inflow <- read.csv(inflow_filepath)
1733531363859:# calculate bvr inflow temp based on met air temp
1733531363860:# step 1: get daily avg met for entire sim period
1733531363862:met_sub <- met |> dplyr::select(time, AirTemp) |>
1733531363863:dplyr::mutate(time = as.Date(time)) |>
1733531363864:dplyr::group_by(time) |>
1733531363864:dplyr::summarise(mean_airtemp = mean(AirTemp)) |>
1733531363864:dplyr::filter(time<= "2022-05-04")
1733531363865:# step 3: calculate fcr water temp using: weir temp = (0.75 * air temp) + 2.4
1733531363865:fcr_inflow_temp <- (0.75 * met_sub$mean_airtemp) + 2.4
1733531363866:# step 4: calculate bvr inflow temp using: BVR temp = (1.5 * FCR temp) - 9.21
1733531363866:inflow$TEMP <- (1.5 * fcr_inflow_temp) - 9.21
1733531363867:# write to file
1733531363867:new_inflow_filepath <- paste0("./sims/spinup/",scenario_folder_names[i],
1733531363868:"/inputs/inflow_",scenario_folder_names[i],".csv")
1733531363869:write.csv(inflow, new_inflow_filepath, row.names = FALSE, quote = FALSE)
1733531363870:# set nml to use scenario met data
1733531363870:scenario_nml_file <- file.path(paste0("./sims/spinup/",scenario_folder_names[i],"/glm3.nml"))
1733531363870:scenario_nml <- glmtools::read_nml(nml_file = scenario_nml_file)
1733531363871:scenario_nml <- glmtools::set_nml(scenario_nml, arg_list =
1733531363871:list("meteo_fl" = paste0("inputs/met_",scenario_folder_names[i],".csv"),
1733531363872:"inflow_fl" = paste0("inputs/inflow_",scenario_folder_names[i],".csv")))
1733531363872:glmtools::write_nml(scenario_nml, file = scenario_nml_file)
1733531363873:}
1733531369743:# Set start and end dates
1733531369744:start_date <- as.POSIXct("2000-07-08 00:00:00", tz = "UTC")
1733531369746:end_date <- as.POSIXct("2022-05-03 00:00:00", tz = "UTC")
1733531369747:total_hours <- as.numeric(difftime(end_date, start_date, units = "hours")) + 1
1733531369748:total_days <- ceiling(as.numeric(difftime(end_date, start_date, units = "days")) + 1)
1733531369751:# Define the observation period for cycling
1733531369751:obs_start_year <- 2015
1733531369752:obs_end_year <- 2022
1733531369752:obs_years <- seq(obs_start_year, obs_end_year)
1733531369753:# Function to map simulation date to observation date
1733531369753:map_to_obs_date <- function(sim_date, obs, hourly = TRUE) {
1733531369754:# Ensure sim_date is in POSIXct format (adjust if needed)
1733531369754:sim_date <- as.POSIXct(sim_date)
1733531369755:# Get simulation year and month/day
1733531369755:sim_year <- as.numeric(format(sim_date, "%Y"))
1733531369755:month_day <- format(sim_date, "%m-%d")
1733531369756:# Set time to "00:00:00" if hourly is FALSE, otherwise use the actual time from sim_date
1733531369756:time <- if (hourly) format(sim_date, "%H:%M:%S") else "00:00:00"
1733531369757:# Initialize observation year variable
1733531369757:obs_year <- sim_year
1733531369757:# Map simulation years (2000-2015) to observation years (2016-2021)
1733531369758:if (sim_date < as.POSIXct("2015-07-08")) {
1733531369758:if (sim_year >= 2000 && sim_year <= 2015) {
1733531369758:# Map 2000-2015 to 2016-2021 based on the modulo calculation
1733531369759:obs_year <- 2016 + ((sim_year - 2000) %% 6)  # Loop through 2016-2021 (6 years)
1733531369759:}
1733531369759:} else {
1733531369760:# After July 7, 2015, use actual observation years
1733531369760:obs_year <- sim_year
1733531369760:}
1733531369760:# Adjust leap year dates (e.g., February 29th)
1733531369761:if ((obs_year == 2016 || obs_year == 2020 || obs_year == 2024) && month_day == "02-29") {
1733531369761:# If the observation year is a leap year and it's February 29, change to March 1
1733531369762:month_day <- "03-01"
1733531369762:}
1733531369763:# Construct observation date in POSIXct format
1733531369763:obs_date_string <- paste0(obs_year, "-", month_day, " ", time)
1733531369763:obs_date <- as.POSIXct(obs_date_string, format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
1733531369764:# For non-hourly data (just dates), reset time to 00:00:00
1733531369764:if (!hourly) {
1733531369764:obs_date <- as.POSIXct(format(obs_date, "%Y-%m-%d"), tz = "UTC")
1733531369764:}
1733531369765:# Check if obs_date is in obs data and return; if not, return NA
1733531369765:if (!is.na(obs_date) && obs_date %in% obs$time) {
1733531369765:return(obs_date)
1733531369766:} else {
1733531369766:if (hourly) {
1733531369766:cat("No match for obs_date:", sim_date, "\n")
1733531369766:}
1733531369766:return(NA)
1733531369766:}
1733531369767:}
1733531369768:# Iterate through each scenario
1733531369768:for (i in 1:length(scenario)) {
1733531369768:# Step 1: Set file paths and update start date in the .nml file
1733531369768:scenario_nml_file <- file.path(paste0("./sims/", scenario[i], "/glm3.nml"))
1733531369769:scenario_nml <- glmtools::read_nml(nml_file = scenario_nml_file)
1733531369769:scenario_nml <- glmtools::set_nml(scenario_nml, arg_name = "start",
1733531369769:arg_val = format(start_date, "%Y-%m-%d %H:%M:%S"))
1733531369769:glmtools::write_nml(scenario_nml, file = scenario_nml_file)
1733531369769:# Step 2: Adjust the met files
1733531369769:met_file <- if (scenario[i] == "baseline") {
1733531369770:paste0("sims/", scenario[i], "/inputs/met.csv")
1733531369770:} else {
1733531369770:paste0("sims/", scenario[i], "/inputs/met_", scenario[i], ".csv")
1733531369770:}
1733531369770:met <- read.csv(met_file) |>
1733531369771:dplyr::mutate(time = as.POSIXct(paste0(time, ":00"),
1733531369771:format = "%Y-%m-%d %H:%M:%S", tz = "UTC")) |>
1733531369771:dplyr::filter(time >= as.POSIXct("2015-07-08"))
1733531369771:# Generate the sequence of simulation dates
1733531369771:expanded_times <- seq(start_date, by = "hour", length.out = total_hours)
1733531369772:# Map simulation times to observation times
1733531369772:mapped_times <- vapply(expanded_times, function(sim_date) {
1733531369772:map_to_obs_date(sim_date, met)
1733531369772:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733531369773:mapped_times <- as.POSIXct(mapped_times, format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
1733531369773:# Create the expanded met data frame
1733531369773:expanded_met <- data.frame(
1733531369773:time = expanded_times,
1733531369774:obs_time = mapped_times
1733531369774:)
1733531369774:# Join with met based on obs_time to get corresponding observations
1733531369774:expanded_met <- merge(expanded_met, met, by.x = "obs_time",
1733531369775:by.y = "time", all.x = TRUE) |>
1733531369775:dplyr::select(-obs_time) |>
1733531369775:arrange(time) %>%
1733531369775:mutate(
1733531369775:AirTemp = ifelse(as.Date(time) == "2008-02-29" & is.na(AirTemp),
1733531369776:AirTemp[which(as.Date(time) == "2008-02-28")],
1733531369776:AirTemp),
1733531369776:Shortwave = ifelse(as.Date(time) == "2008-02-29" & is.na(Shortwave),
1733531369776:Shortwave[which(as.Date(time) == "2008-02-28")],
1733531369776:Shortwave),
1733531369777:Longwave = ifelse(as.Date(time) == "2008-02-29" & is.na(Longwave),
1733531369777:Longwave[which(as.Date(time) == "2008-02-28")],
1733531369777:Longwave),
1733531369777:RelHum = ifelse(as.Date(time) == "2008-02-29" & is.na(RelHum),
1733531369777:RelHum[which(as.Date(time) == "2008-02-28")],
1733531369778:RelHum),
1733531369778:WindSpeed = ifelse(as.Date(time) == "2008-02-29" & is.na(WindSpeed),
1733531369778:WindSpeed[which(as.Date(time) == "2008-02-28")],
1733531369778:WindSpeed),
1733531369779:Rain = ifelse(as.Date(time) == "2008-02-29" & is.na(Rain),
1733531369779:Rain[which(as.Date(time) == "2008-02-28")],
1733531369779:Rain),
1733531369779:Snow = ifelse(as.Date(time) == "2008-02-29" & is.na(Snow),
1733531369779:Snow[which(as.Date(time) == "2008-02-28")],
1733531369780:Snow)
1733531369780:)
1733531369780:# Save met file
1733531369781:if(scenario[i]=="baseline"){
1733531369781:write.csv(expanded_met, paste0("sims/spinup/",scenario[i],"/inputs/met.csv"),
1733531369781:row.names = FALSE)
1733531369781:} else{
1733531369782:write.csv(expanded_met, paste0("sims/spinup/",scenario[i],"/inputs/met_",scenario[i],".csv"),
1733531369782:row.names = FALSE)
1733531369782:}
1733531369783:# Step 3: Adjust the inflow file similarly
1733531369783:inflow_file <- if (scenario[i] == "baseline") {
1733531369783:"sims/baseline/inputs/BVR_inflow_2015_2022_allfractions_2poolsDOC_withch4_metInflow_0.65X_silica_0.2X_nitrate_0.4X_ammonium_1.9X_docr_1.7Xdoc.csv"
1733531369784:} else {
1733531369784:paste0("sims/", scenario[i], "/inputs/inflow_", scenario[i], ".csv")
1733531369785:}
1733531369785:inflow <- read.csv(inflow_file) |>
1733531369785:dplyr::mutate(time = as.POSIXct(
1733531369785:paste(time,"00:00:00"),
1733531369786:format = "%Y-%m-%d %H:%M:%S", tz = "UTC"))
1733531369786:# Generate the sequence of simulation dates
1733531369786:expanded_times <- seq(as.Date(start_date), by = "day",
1733531369787:length.out = total_days)
1733531369787:# Map simulation times to observation times
1733531369787:mapped_days_inflow <- vapply(expanded_times, function(sim_date) {
1733531369788:map_to_obs_date(sim_date, inflow, hourly = FALSE)
1733531369788:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733531369789:mapped_days_inflow <- as.POSIXct(mapped_days_inflow, format = "%Y-%m-%d", tz = "UTC")
1733531369789:# Create the expanded inflow data frame
1733531369790:expanded_inflow <- data.frame(
1733531369790:time = expanded_times,
1733531369790:obs_time = mapped_days_inflow
1733531369791:)
1733531369791:# Join with met based on obs_time to get corresponding observations
1733531369791:expanded_inflow <- merge(expanded_inflow, inflow, by.x = "obs_time",
1733531369792:by.y = "time", all.x = TRUE) |>
1733531369792:dplyr::select(-obs_time) |>
1733531369792:arrange(time) |>
1733531369793:mutate(time = coalesce(time, lag(time)))
1733531369793:# Save inflow file
1733531369793:if(scenario[i]=="baseline"){
1733531369794:write.csv(expanded_inflow, paste0("sims/spinup/",scenario[i],"/inputs/BVR_inflow_2015_2022_allfractions_2poolsDOC_withch4_metInflow_0.65X_silica_0.2X_nitrate_0.4X_ammonium_1.9X_docr_1.7Xdoc.csv"),
1733531369794:row.names = FALSE)
1733531369795:} else{
1733531369795:write.csv(expanded_inflow, paste0("sims/spinup/",scenario[i],"/inputs/inflow_",scenario[i],".csv"),
1733531369795:row.names = FALSE)
1733531369796:}
1733531369796:# Step 4: Adjust the outflow file
1733531369796:outflow_file <- "sims/baseline/inputs/BVR_spillway_outflow_2015_2022_metInflow.csv"
1733531369797:outflow <- read.csv(outflow_file) |>
1733531369797:dplyr::mutate(time = as.POSIXct(
1733531369797:paste(time,"00:00:00"),
1733531369798:format = "%Y-%m-%d %H:%M:%S", tz = "UTC"))
1733531369798:# Generate the sequence of simulation dates
1733531369799:expanded_times <- seq(as.Date(start_date), by = "day",
1733531369799:length.out = total_days)
1733531369800:# Map simulation times to observation times
1733531369800:mapped_days_outflow <- vapply(expanded_times, function(sim_date) {
1733531369800:map_to_obs_date(sim_date, outflow, hourly = FALSE)
1733531369801:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733531369802:mapped_days_outflow <- as.POSIXct(mapped_days_outflow,
1733531369802:format = "%Y-%m-%d", tz = "UTC")
1733531369804:# Replace NA values with the previous valid datetime
1733531369805:mapped_days_outflow <- na.locf(mapped_days_outflow, na.rm = FALSE)
1733531369806:# Create the expanded met data frame
1733531369806:expanded_outflow <- data.frame(
1733531369807:time = expanded_times,
1733531369808:obs_time = mapped_days_outflow
1733531369808:)
1733531369809:# Join with met based on obs_time to get corresponding observations
1733531369810:expanded_outflow <- merge(expanded_outflow, outflow, by.x = "obs_time",
1733531369810:by.y = "time", all.x = TRUE) |>
1733531369811:dplyr::select(-obs_time) |>
1733531369811:arrange(time)  |>
1733531369812:mutate(time = coalesce(time, lag(time)))
1733531369813:# Save the file
1733531369813:write.csv(expanded_outflow, paste0("sims/spinup/",scenario[i],"/inputs/BVR_spillway_outflow_2015_2022_metInflow.csv"),
1733531369814:row.names = FALSE)
1733531369814:}
1733531744353:View(expanded_met)
1733531751204:head(met)
1733531775372:# create a folder for each scenarios and populate with sim files
1733531775373:glm_files = list.files("./sims/baseline", full.names = TRUE)[1:3]
1733531775539:#list of scenarios
1733531775539:scenario <- c("baseline","plus1","plus5","plus10")
1733531775677:for (i in 1:length(scenario)){
1733531775678:subdirName <- paste0("./sims/spinup/",scenario[i])
1733531775678:folder<-dir.create(subdirName)
1733531775679:file.copy(from = glm_files, to = subdirName, recursive = TRUE)
1733531775679:outputdirName <- paste0(subdirName,"/output")
1733531775679:output_folder<-dir.create(outputdirName)
1733531775683:}
1733531776864:# assign names to scenarios
1733531776864:scenario_folder_names <- c("plus1","plus5","plus10")
1733531776865:# add corresponding degrees C to met Temp_C column for each scenario
1733531776865:temp_increments <- c(1,5,10)
1733531776867:for (i in 1:length(scenario_folder_names)){
1733531776870:# get met data filepath and read in met data
1733531776871:met_filepath <- paste0("./sims/",scenario_folder_names[i],"/inputs/met.csv")
1733531776872:met <- read.csv(met_filepath)
1733531776872:# add temp increments
1733531776873:met$AirTemp <- met$AirTemp + temp_increments[i]
1733531776875:# write to file
1733531776875:new_met_filepath <- paste0("./sims/spinup/",scenario_folder_names[i],"/inputs/met_",scenario_folder_names[i],".csv")
1733531776875:write.csv(met, new_met_filepath, row.names = FALSE, quote = FALSE)
1733531776878:# get inflow data filepath and read in data
1733531776879:inflow_filepath <- paste0("./sims/",scenario_folder_names[i],
1733531776879:"/inputs/BVR_inflow_2015_2022_allfractions_2poolsDOC_withch4_metInflow_0.65X_silica_0.2X_nitrate_0.4X_ammonium_1.9X_docr_1.7Xdoc.csv")
1733531776879:inflow <- read.csv(inflow_filepath)
1733531776880:# calculate bvr inflow temp based on met air temp
1733531776880:# step 1: get daily avg met for entire sim period
1733531776881:met_sub <- met |> dplyr::select(time, AirTemp) |>
1733531776881:dplyr::mutate(time = as.Date(time)) |>
1733531776881:dplyr::group_by(time) |>
1733531776882:dplyr::summarise(mean_airtemp = mean(AirTemp)) |>
1733531776882:dplyr::filter(time<= "2022-05-04")
1733531776883:# step 3: calculate fcr water temp using: weir temp = (0.75 * air temp) + 2.4
1733531776883:fcr_inflow_temp <- (0.75 * met_sub$mean_airtemp) + 2.4
1733531776884:# step 4: calculate bvr inflow temp using: BVR temp = (1.5 * FCR temp) - 9.21
1733531776885:inflow$TEMP <- (1.5 * fcr_inflow_temp) - 9.21
1733531776885:# write to file
1733531776886:new_inflow_filepath <- paste0("./sims/spinup/",scenario_folder_names[i],
1733531776886:"/inputs/inflow_",scenario_folder_names[i],".csv")
1733531776886:write.csv(inflow, new_inflow_filepath, row.names = FALSE, quote = FALSE)
1733531776887:# set nml to use scenario met data
1733531776887:scenario_nml_file <- file.path(paste0("./sims/spinup/",scenario_folder_names[i],"/glm3.nml"))
1733531776887:scenario_nml <- glmtools::read_nml(nml_file = scenario_nml_file)
1733531776888:scenario_nml <- glmtools::set_nml(scenario_nml, arg_list =
1733531776888:list("meteo_fl" = paste0("inputs/met_",scenario_folder_names[i],".csv"),
1733531776889:"inflow_fl" = paste0("inputs/inflow_",scenario_folder_names[i],".csv")))
1733531776889:glmtools::write_nml(scenario_nml, file = scenario_nml_file)
1733531776889:}
1733531783634:# Set start and end dates
1733531783635:start_date <- as.POSIXct("2000-07-08 00:00:00", tz = "UTC")
1733531783636:end_date <- as.POSIXct("2022-05-03 00:00:00", tz = "UTC")
1733531783636:total_hours <- as.numeric(difftime(end_date, start_date, units = "hours")) + 1
1733531783637:total_days <- ceiling(as.numeric(difftime(end_date, start_date, units = "days")) + 1)
1733531783637:# Define the observation period for cycling
1733531783637:obs_start_year <- 2015
1733531783637:obs_end_year <- 2022
1733531783638:obs_years <- seq(obs_start_year, obs_end_year)
1733531783638:# Function to map simulation date to observation date
1733531783638:map_to_obs_date <- function(sim_date, obs, hourly = TRUE) {
1733531783639:# Ensure sim_date is in POSIXct format (adjust if needed)
1733531783639:sim_date <- as.POSIXct(sim_date)
1733531783639:# Get simulation year and month/day
1733531783639:sim_year <- as.numeric(format(sim_date, "%Y"))
1733531783640:month_day <- format(sim_date, "%m-%d")
1733531783640:# Set time to "00:00:00" if hourly is FALSE, otherwise use the actual time from sim_date
1733531783640:time <- if (hourly) format(sim_date, "%H:%M:%S") else "00:00:00"
1733531783641:# Initialize observation year variable
1733531783641:obs_year <- sim_year
1733531783641:# Map simulation years (2000-2015) to observation years (2016-2021)
1733531783642:if (sim_date < as.POSIXct("2015-07-08")) {
1733531783642:if (sim_year >= 2000 && sim_year <= 2015) {
1733531783642:# Map 2000-2015 to 2016-2021 based on the modulo calculation
1733531783643:obs_year <- 2016 + ((sim_year - 2000) %% 6)  # Loop through 2016-2021 (6 years)
1733531783643:}
1733531783643:} else {
1733531783643:# After July 7, 2015, use actual observation years
1733531783644:obs_year <- sim_year
1733531783644:}
1733531783645:# Adjust leap year dates (e.g., February 29th)
1733531783645:if ((obs_year == 2016 || obs_year == 2020 || obs_year == 2024) && month_day == "02-29") {
1733531783646:# If the observation year is a leap year and it's February 29, change to March 1
1733531783646:month_day <- "03-01"
1733531783647:}
1733531783647:# Construct observation date in POSIXct format
1733531783648:obs_date_string <- paste0(obs_year, "-", month_day, " ", time)
1733531783648:obs_date <- as.POSIXct(obs_date_string, format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
1733531783648:# For non-hourly data (just dates), reset time to 00:00:00
1733531783649:if (!hourly) {
1733531783649:obs_date <- as.POSIXct(format(obs_date, "%Y-%m-%d"), tz = "UTC")
1733531783649:}
1733531783650:# Check if obs_date is in obs data and return; if not, return NA
1733531783650:if (!is.na(obs_date) && obs_date %in% obs$time) {
1733531783651:return(obs_date)
1733531783651:} else {
1733531783652:if (hourly) {
1733531783652:cat("No match for obs_date:", sim_date, "\n")
1733531783652:}
1733531783652:return(NA)
1733531783653:}
1733531783653:}
1733531783655:# Iterate through each scenario
1733531783655:for (i in 1:length(scenario)) {
1733531783656:# Step 1: Set file paths and update start date in the .nml file
1733531783656:scenario_nml_file <- file.path(paste0("./sims/", scenario[i], "/glm3.nml"))
1733531783656:scenario_nml <- glmtools::read_nml(nml_file = scenario_nml_file)
1733531783657:scenario_nml <- glmtools::set_nml(scenario_nml, arg_name = "start",
1733531783657:arg_val = format(start_date, "%Y-%m-%d %H:%M:%S"))
1733531783657:glmtools::write_nml(scenario_nml, file = scenario_nml_file)
1733531783657:# Step 2: Adjust the met files
1733531783658:met_file <- if (scenario[i] == "baseline") {
1733531783658:paste0("sims/", scenario[i], "/inputs/met.csv")
1733531783658:} else {
1733531783658:paste0("sims/", scenario[i], "/inputs/met_", scenario[i], ".csv")
1733531783659:}
1733531783659:met <- read.csv(met_file) |>
1733531783659:dplyr::mutate(time = as.POSIXct(paste0(time, ":00"),
1733531783659:format = "%Y-%m-%d %H:%M:%S", tz = "UTC")) |>
1733531783659:dplyr::filter(time >= as.POSIXct("2015-07-08"))
1733531783660:# Generate the sequence of simulation dates
1733531783660:expanded_times <- seq(start_date, by = "hour", length.out = total_hours)
1733531783661:# Map simulation times to observation times
1733531783661:mapped_times <- vapply(expanded_times, function(sim_date) {
1733531783661:map_to_obs_date(sim_date, met)
1733531783661:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733531783662:mapped_times <- as.POSIXct(mapped_times, format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
1733531783662:# Create the expanded met data frame
1733531783663:expanded_met <- data.frame(
1733531783663:time = expanded_times,
1733531783663:obs_time = mapped_times
1733531783663:)
1733531783664:# Join with met based on obs_time to get corresponding observations
1733531783664:expanded_met <- merge(expanded_met, met, by.x = "obs_time",
1733531783664:by.y = "time", all.x = TRUE) |>
1733531783664:dplyr::select(-obs_time) |>
1733531783665:arrange(time) %>%
1733531783665:mutate(
1733531783665:AirTemp = ifelse(as.Date(time) == "2008-02-29" & is.na(AirTemp),
1733531783665:AirTemp[which(as.Date(time) == "2008-02-28")],
1733531783665:AirTemp),
1733531783666:ShortWave = ifelse(as.Date(time) == "2008-02-29" & is.na(ShortWave),
1733531783666:ShortWave[which(as.Date(time) == "2008-02-28")],
1733531783667:ShortWave),
1733531783667:LongWave = ifelse(as.Date(time) == "2008-02-29" & is.na(LongWave),
1733531783667:LongWave[which(as.Date(time) == "2008-02-28")],
1733531783667:LongWave),
1733531783668:RelHum = ifelse(as.Date(time) == "2008-02-29" & is.na(RelHum),
1733531783668:RelHum[which(as.Date(time) == "2008-02-28")],
1733531783668:RelHum),
1733531783668:WindSpeed = ifelse(as.Date(time) == "2008-02-29" & is.na(WindSpeed),
1733531783669:WindSpeed[which(as.Date(time) == "2008-02-28")],
1733531783669:WindSpeed),
1733531783669:Rain = ifelse(as.Date(time) == "2008-02-29" & is.na(Rain),
1733531783670:Rain[which(as.Date(time) == "2008-02-28")],
1733531783670:Rain),
1733531783670:Snow = ifelse(as.Date(time) == "2008-02-29" & is.na(Snow),
1733531783671:Snow[which(as.Date(time) == "2008-02-28")],
1733531783671:Snow)
1733531783671:)
1733531783672:# Save met file
1733531783673:if(scenario[i]=="baseline"){
1733531783673:write.csv(expanded_met, paste0("sims/spinup/",scenario[i],"/inputs/met.csv"),
1733531783674:row.names = FALSE)
1733531783674:} else{
1733531783675:write.csv(expanded_met, paste0("sims/spinup/",scenario[i],"/inputs/met_",scenario[i],".csv"),
1733531783675:row.names = FALSE)
1733531783676:}
1733531783677:# Step 3: Adjust the inflow file similarly
1733531783678:inflow_file <- if (scenario[i] == "baseline") {
1733531783678:"sims/baseline/inputs/BVR_inflow_2015_2022_allfractions_2poolsDOC_withch4_metInflow_0.65X_silica_0.2X_nitrate_0.4X_ammonium_1.9X_docr_1.7Xdoc.csv"
1733531783679:} else {
1733531783679:paste0("sims/", scenario[i], "/inputs/inflow_", scenario[i], ".csv")
1733531783679:}
1733531783680:inflow <- read.csv(inflow_file) |>
1733531783680:dplyr::mutate(time = as.POSIXct(
1733531783680:paste(time,"00:00:00"),
1733531783681:format = "%Y-%m-%d %H:%M:%S", tz = "UTC"))
1733531783681:# Generate the sequence of simulation dates
1733531783681:expanded_times <- seq(as.Date(start_date), by = "day",
1733531783682:length.out = total_days)
1733531783682:# Map simulation times to observation times
1733531783683:mapped_days_inflow <- vapply(expanded_times, function(sim_date) {
1733531783683:map_to_obs_date(sim_date, inflow, hourly = FALSE)
1733531783684:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733531783684:mapped_days_inflow <- as.POSIXct(mapped_days_inflow, format = "%Y-%m-%d", tz = "UTC")
1733531783685:# Create the expanded inflow data frame
1733531783685:expanded_inflow <- data.frame(
1733531783686:time = expanded_times,
1733531783686:obs_time = mapped_days_inflow
1733531783686:)
1733531783687:# Join with met based on obs_time to get corresponding observations
1733531783687:expanded_inflow <- merge(expanded_inflow, inflow, by.x = "obs_time",
1733531783688:by.y = "time", all.x = TRUE) |>
1733531783688:dplyr::select(-obs_time) |>
1733531783689:arrange(time) |>
1733531783689:mutate(time = coalesce(time, lag(time)))
1733531783689:# Save inflow file
1733531783690:if(scenario[i]=="baseline"){
1733531783690:write.csv(expanded_inflow, paste0("sims/spinup/",scenario[i],"/inputs/BVR_inflow_2015_2022_allfractions_2poolsDOC_withch4_metInflow_0.65X_silica_0.2X_nitrate_0.4X_ammonium_1.9X_docr_1.7Xdoc.csv"),
1733531783690:row.names = FALSE)
1733531783691:} else{
1733531783692:write.csv(expanded_inflow, paste0("sims/spinup/",scenario[i],"/inputs/inflow_",scenario[i],".csv"),
1733531783692:row.names = FALSE)
1733531783692:}
1733531783693:# Step 4: Adjust the outflow file
1733531783693:outflow_file <- "sims/baseline/inputs/BVR_spillway_outflow_2015_2022_metInflow.csv"
1733531783694:outflow <- read.csv(outflow_file) |>
1733531783694:dplyr::mutate(time = as.POSIXct(
1733531783695:paste(time,"00:00:00"),
1733531783696:format = "%Y-%m-%d %H:%M:%S", tz = "UTC"))
1733531783696:# Generate the sequence of simulation dates
1733531783697:expanded_times <- seq(as.Date(start_date), by = "day",
1733531783697:length.out = total_days)
1733531783698:# Map simulation times to observation times
1733531783699:mapped_days_outflow <- vapply(expanded_times, function(sim_date) {
1733531783699:map_to_obs_date(sim_date, outflow, hourly = FALSE)
1733531783699:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733531783700:mapped_days_outflow <- as.POSIXct(mapped_days_outflow,
1733531783701:format = "%Y-%m-%d", tz = "UTC")
1733531783701:# Replace NA values with the previous valid datetime
1733531783702:mapped_days_outflow <- na.locf(mapped_days_outflow, na.rm = FALSE)
1733531783702:# Create the expanded met data frame
1733531783703:expanded_outflow <- data.frame(
1733531783703:time = expanded_times,
1733531783703:obs_time = mapped_days_outflow
1733531783704:)
1733531783705:# Join with met based on obs_time to get corresponding observations
1733531783705:expanded_outflow <- merge(expanded_outflow, outflow, by.x = "obs_time",
1733531783705:by.y = "time", all.x = TRUE) |>
1733531783706:dplyr::select(-obs_time) |>
1733531783706:arrange(time)  |>
1733531783706:mutate(time = coalesce(time, lag(time)))
1733531783707:# Save the file
1733531783708:write.csv(expanded_outflow, paste0("sims/spinup/",scenario[i],"/inputs/BVR_spillway_outflow_2015_2022_metInflow.csv"),
1733531783708:row.names = FALSE)
1733531783708:}
1733531966856:# create a folder for each scenarios and populate with sim files
1733531966857:glm_files = list.files("./sims/baseline", full.names = TRUE)[1:3]
1733531967273:#list of scenarios
1733531967273:scenario <- c("baseline","plus1","plus5","plus10")
1733531968034:for (i in 1:length(scenario)){
1733531968035:subdirName <- paste0("./sims/spinup/",scenario[i])
1733531968035:folder<-dir.create(subdirName)
1733531968036:file.copy(from = glm_files, to = subdirName, recursive = TRUE)
1733531968036:outputdirName <- paste0(subdirName,"/output")
1733531968038:output_folder<-dir.create(outputdirName)
1733531968039:}
1733531969521:# assign names to scenarios
1733531969521:scenario_folder_names <- c("plus1","plus5","plus10")
1733531969522:# add corresponding degrees C to met Temp_C column for each scenario
1733531969522:temp_increments <- c(1,5,10)
1733531969523:for (i in 1:length(scenario_folder_names)){
1733531969523:# get met data filepath and read in met data
1733531969523:met_filepath <- paste0("./sims/",scenario_folder_names[i],"/inputs/met.csv")
1733531969524:met <- read.csv(met_filepath)
1733531969524:# add temp increments
1733531969524:met$AirTemp <- met$AirTemp + temp_increments[i]
1733531969524:# write to file
1733531969525:new_met_filepath <- paste0("./sims/spinup/",scenario_folder_names[i],"/inputs/met_",scenario_folder_names[i],".csv")
1733531969525:write.csv(met, new_met_filepath, row.names = FALSE, quote = FALSE)
1733531969525:# get inflow data filepath and read in data
1733531969525:inflow_filepath <- paste0("./sims/",scenario_folder_names[i],
1733531969526:"/inputs/BVR_inflow_2015_2022_allfractions_2poolsDOC_withch4_metInflow_0.65X_silica_0.2X_nitrate_0.4X_ammonium_1.9X_docr_1.7Xdoc.csv")
1733531969526:inflow <- read.csv(inflow_filepath)
1733531969526:# calculate bvr inflow temp based on met air temp
1733531969526:# step 1: get daily avg met for entire sim period
1733531969527:met_sub <- met |> dplyr::select(time, AirTemp) |>
1733531969527:dplyr::mutate(time = as.Date(time)) |>
1733531969527:dplyr::group_by(time) |>
1733531969527:dplyr::summarise(mean_airtemp = mean(AirTemp)) |>
1733531969527:dplyr::filter(time<= "2022-05-04")
1733531969528:# step 3: calculate fcr water temp using: weir temp = (0.75 * air temp) + 2.4
1733531969528:fcr_inflow_temp <- (0.75 * met_sub$mean_airtemp) + 2.4
1733531969531:# step 4: calculate bvr inflow temp using: BVR temp = (1.5 * FCR temp) - 9.21
1733531969531:inflow$TEMP <- (1.5 * fcr_inflow_temp) - 9.21
1733531969532:# write to file
1733531969532:new_inflow_filepath <- paste0("./sims/spinup/",scenario_folder_names[i],
1733531969532:"/inputs/inflow_",scenario_folder_names[i],".csv")
1733531969532:write.csv(inflow, new_inflow_filepath, row.names = FALSE, quote = FALSE)
1733531969533:# set nml to use scenario met data
1733531969533:scenario_nml_file <- file.path(paste0("./sims/spinup/",scenario_folder_names[i],"/glm3.nml"))
1733531969533:scenario_nml <- glmtools::read_nml(nml_file = scenario_nml_file)
1733531969533:scenario_nml <- glmtools::set_nml(scenario_nml, arg_list =
1733531969534:list("meteo_fl" = paste0("inputs/met_",scenario_folder_names[i],".csv"),
1733531969534:"inflow_fl" = paste0("inputs/inflow_",scenario_folder_names[i],".csv")))
1733531969534:glmtools::write_nml(scenario_nml, file = scenario_nml_file)
1733531969534:}
1733531981784:# Set start and end dates
1733531981784:start_date <- as.POSIXct("2000-07-08 00:00:00", tz = "UTC")
1733531981784:end_date <- as.POSIXct("2022-05-03 00:00:00", tz = "UTC")
1733531981785:total_hours <- as.numeric(difftime(end_date, start_date, units = "hours")) + 1
1733531981785:total_days <- ceiling(as.numeric(difftime(end_date, start_date, units = "days")) + 1)
1733531981785:# Define the observation period for cycling
1733531981786:obs_start_year <- 2015
1733531981786:obs_end_year <- 2022
1733531981786:obs_years <- seq(obs_start_year, obs_end_year)
1733531981786:# Function to map simulation date to observation date
1733531981786:map_to_obs_date <- function(sim_date, obs, hourly = TRUE) {
1733531981786:# Ensure sim_date is in POSIXct format (adjust if needed)
1733531981787:sim_date <- as.POSIXct(sim_date)
1733531981787:# Get simulation year and month/day
1733531981787:sim_year <- as.numeric(format(sim_date, "%Y"))
1733531981787:month_day <- format(sim_date, "%m-%d")
1733531981787:# Set time to "00:00:00" if hourly is FALSE, otherwise use the actual time from sim_date
1733531981787:time <- if (hourly) format(sim_date, "%H:%M:%S") else "00:00:00"
1733531981787:# Initialize observation year variable
1733531981788:obs_year <- sim_year
1733531981788:# Map simulation years (2000-2015) to observation years (2016-2021)
1733531981788:if (sim_date < as.POSIXct("2015-07-08")) {
1733531981788:if (sim_year >= 2000 && sim_year <= 2015) {
1733531981788:# Map 2000-2015 to 2016-2021 based on the modulo calculation
1733531981788:obs_year <- 2016 + ((sim_year - 2000) %% 6)  # Loop through 2016-2021 (6 years)
1733531981788:}
1733531981788:} else {
1733531981789:# After July 7, 2015, use actual observation years
1733531981789:obs_year <- sim_year
1733531981789:}
1733531981789:# Adjust leap year dates (e.g., February 29th)
1733531981789:if ((obs_year == 2016 || obs_year == 2020 || obs_year == 2024) && month_day == "02-29") {
1733531981789:# If the observation year is a leap year and it's February 29, change to March 1
1733531981789:month_day <- "03-01"
1733531981790:}
1733531981790:# Construct observation date in POSIXct format
1733531981790:obs_date_string <- paste0(obs_year, "-", month_day, " ", time)
1733531981790:obs_date <- as.POSIXct(obs_date_string, format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
1733531981790:# For non-hourly data (just dates), reset time to 00:00:00
1733531981790:if (!hourly) {
1733531981791:obs_date <- as.POSIXct(format(obs_date, "%Y-%m-%d"), tz = "UTC")
1733531981791:}
1733531981791:# Check if obs_date is in obs data and return; if not, return NA
1733531981791:if (!is.na(obs_date) && obs_date %in% obs$time) {
1733531981791:return(obs_date)
1733531981791:} else {
1733531981792:if (hourly) {
1733531981792:cat("No match for obs_date:", sim_date, "\n")
1733531981792:}
1733531981792:return(NA)
1733531981792:}
1733531981792:}
1733531981793:# Iterate through each scenario
1733531981793:for (i in 1:length(scenario)) {
1733531981793:# Step 1: Set file paths and update start date in the .nml file
1733531981793:scenario_nml_file <- file.path(paste0("./sims/", scenario[i], "/glm3.nml"))
1733531981793:scenario_nml <- glmtools::read_nml(nml_file = scenario_nml_file)
1733531981794:scenario_nml <- glmtools::set_nml(scenario_nml, arg_name = "start",
1733531981794:arg_val = format(start_date, "%Y-%m-%d %H:%M:%S"))
1733531981794:glmtools::write_nml(scenario_nml, file = scenario_nml_file)
1733531981794:# Step 2: Adjust the met files
1733531981795:met_file <- if (scenario[i] == "baseline") {
1733531981795:paste0("sims/", scenario[i], "/inputs/met.csv")
1733531981795:} else {
1733531981795:paste0("sims/", scenario[i], "/inputs/met_", scenario[i], ".csv")
1733531981796:}
1733531981796:met <- read.csv(met_file) |>
1733531981796:dplyr::mutate(time = as.POSIXct(paste0(time, ":00"),
1733531981797:format = "%Y-%m-%d %H:%M:%S", tz = "UTC")) |>
1733531981797:dplyr::filter(time >= as.POSIXct("2015-07-08"))
1733531981797:# Generate the sequence of simulation dates
1733531981797:expanded_times <- seq(start_date, by = "hour", length.out = total_hours)
1733531981798:# Map simulation times to observation times
1733531981798:mapped_times <- vapply(expanded_times, function(sim_date) {
1733531981798:map_to_obs_date(sim_date, met)
1733531981799:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733531981799:mapped_times <- as.POSIXct(mapped_times, format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
1733531981800:# Create the expanded met data frame
1733531981800:expanded_met <- data.frame(
1733531981800:time = expanded_times,
1733531981800:obs_time = mapped_times
1733531981800:)
1733531981801:# Join with met based on obs_time to get corresponding observations
1733531981801:expanded_met <- merge(expanded_met, met, by.x = "obs_time",
1733531981801:by.y = "time", all.x = TRUE) |>
1733531981802:dplyr::select(-obs_time) |>
1733531981802:arrange(time) %>%
1733531981803:mutate(
1733531981804:AirTemp = ifelse(as.Date(time) == "2008-02-29" & is.na(AirTemp),
1733531981805:AirTemp[which(as.Date(time) == "2008-02-28")],
1733531981805:AirTemp),
1733531981806:ShortWave = ifelse(as.Date(time) == "2008-02-29" & is.na(ShortWave),
1733531981806:ShortWave[which(as.Date(time) == "2008-02-28")],
1733531981806:ShortWave),
1733531981807:LongWave = ifelse(as.Date(time) == "2008-02-29" & is.na(LongWave),
1733531981807:LongWave[which(as.Date(time) == "2008-02-28")],
1733531981808:LongWave),
1733531981808:RelHum = ifelse(as.Date(time) == "2008-02-29" & is.na(RelHum),
1733531981809:RelHum[which(as.Date(time) == "2008-02-28")],
1733531981809:RelHum),
1733531981809:WindSpeed = ifelse(as.Date(time) == "2008-02-29" & is.na(WindSpeed),
1733531981809:WindSpeed[which(as.Date(time) == "2008-02-28")],
1733531981810:WindSpeed),
1733531981810:Rain = ifelse(as.Date(time) == "2008-02-29" & is.na(Rain),
1733531981810:Rain[which(as.Date(time) == "2008-02-28")],
1733531981810:Rain),
1733531981810:Snow = ifelse(as.Date(time) == "2008-02-29" & is.na(Snow),
1733531981811:Snow[which(as.Date(time) == "2008-02-28")],
1733531981811:Snow)
1733531981811:)
1733531981811:# Save met file
1733531981812:if(scenario[i]=="baseline"){
1733531981812:write.csv(expanded_met, paste0("sims/spinup/",scenario[i],"/inputs/met.csv"),
1733531981812:row.names = FALSE)
1733531981812:} else{
1733531981812:write.csv(expanded_met, paste0("sims/spinup/",scenario[i],"/inputs/met_",scenario[i],".csv"),
1733531981813:row.names = FALSE)
1733531981813:}
1733531981813:# Step 3: Adjust the inflow file similarly
1733531981813:inflow_file <- if (scenario[i] == "baseline") {
1733531981814:"sims/baseline/inputs/BVR_inflow_2015_2022_allfractions_2poolsDOC_withch4_metInflow_0.65X_silica_0.2X_nitrate_0.4X_ammonium_1.9X_docr_1.7Xdoc.csv"
1733531981814:} else {
1733531981814:paste0("sims/", scenario[i], "/inputs/inflow_", scenario[i], ".csv")
1733531981814:}
1733531981815:inflow <- read.csv(inflow_file) |>
1733531981815:dplyr::mutate(time = as.POSIXct(
1733531981815:paste(time,"00:00:00"),
1733531981815:format = "%Y-%m-%d %H:%M:%S", tz = "UTC"))
1733531981816:# Generate the sequence of simulation dates
1733531981816:expanded_times <- seq(as.Date(start_date), by = "day",
1733531981816:length.out = total_days)
1733531981817:# Map simulation times to observation times
1733531981817:mapped_days_inflow <- vapply(expanded_times, function(sim_date) {
1733531981817:map_to_obs_date(sim_date, inflow, hourly = FALSE)
1733531981818:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733531981818:mapped_days_inflow <- as.POSIXct(mapped_days_inflow, format = "%Y-%m-%d", tz = "UTC")
1733531981818:# Create the expanded inflow data frame
1733531981819:expanded_inflow <- data.frame(
1733531981819:time = expanded_times,
1733531981819:obs_time = mapped_days_inflow
1733531981820:)
1733531981820:# Join with met based on obs_time to get corresponding observations
1733531981820:expanded_inflow <- merge(expanded_inflow, inflow, by.x = "obs_time",
1733531981821:by.y = "time", all.x = TRUE) |>
1733531981821:dplyr::select(-obs_time) |>
1733531981821:arrange(time) |>
1733531981822:mutate(time = coalesce(time, lag(time)))
1733531981822:# Save inflow file
1733531981822:if(scenario[i]=="baseline"){
1733531981823:write.csv(expanded_inflow, paste0("sims/spinup/",scenario[i],"/inputs/BVR_inflow_2015_2022_allfractions_2poolsDOC_withch4_metInflow_0.65X_silica_0.2X_nitrate_0.4X_ammonium_1.9X_docr_1.7Xdoc.csv"),
1733531981823:row.names = FALSE)
1733531981823:} else{
1733531981824:write.csv(expanded_inflow, paste0("sims/spinup/",scenario[i],"/inputs/inflow_",scenario[i],".csv"),
1733531981824:row.names = FALSE)
1733531981824:}
1733531981825:# Step 4: Adjust the outflow file
1733531981825:outflow_file <- "sims/baseline/inputs/BVR_spillway_outflow_2015_2022_metInflow.csv"
1733531981825:outflow <- read.csv(outflow_file) |>
1733531981826:dplyr::mutate(time = as.POSIXct(
1733531981826:paste(time,"00:00:00"),
1733531981826:format = "%Y-%m-%d %H:%M:%S", tz = "UTC"))
1733531981827:# Generate the sequence of simulation dates
1733531981827:expanded_times <- seq(as.Date(start_date), by = "day",
1733531981827:length.out = total_days)
1733531981828:# Map simulation times to observation times
1733531981828:mapped_days_outflow <- vapply(expanded_times, function(sim_date) {
1733531981828:map_to_obs_date(sim_date, outflow, hourly = FALSE)
1733531981829:}, FUN.VALUE = as.POSIXct(NA, tz = "UTC"))
1733531981830:mapped_days_outflow <- as.POSIXct(mapped_days_outflow,
1733531981830:format = "%Y-%m-%d", tz = "UTC")
1733531981831:# Create the expanded met data frame
1733531981831:expanded_outflow <- data.frame(
1733531981831:time = expanded_times,
1733531981831:obs_time = mapped_days_outflow
1733531981832:)
1733531981832:# Join with met based on obs_time to get corresponding observations
1733531981832:expanded_outflow <- merge(expanded_outflow, outflow, by.x = "obs_time",
1733531981833:by.y = "time", all.x = TRUE) |>
1733531981833:dplyr::select(-obs_time) |>
1733531981833:arrange(time)  |>
1733531981834:mutate(time = coalesce(time, lag(time)))
1733531981834:# Save the file
1733531981835:write.csv(expanded_outflow, paste0("sims/spinup/",scenario[i],"/inputs/BVR_spillway_outflow_2015_2022_metInflow.csv"),
1733531981835:row.names = FALSE)
1733531981836:}
1733533037898:#list of scenarios
1733533037902:scenario <- c("baseline","plus1","plus5","plus10")
1733533042943:# run and plot each scenario
1733533042945:for (i in 1:length(scenario)){
1733533042945:# run the model
1733533042945:sim_folder = paste0("./sims/spinup/",scenario[i])
1733533042946:GLM3r::run_glm(sim_folder)
1733533042946:# set nml file
1733533042946:nc_file <- file.path(paste0("sims/spinup/",scenario[i],"/output/output.nc"))
1733533042946:# access and plot temperature
1733533042957:current_temp <- glmtools::get_var(nc_file, var_name = "temp")
1733533042957:p <- glmtools::plot_var(nc_file, var_name = "temp", reference = "surface",
1733533042958:plot.title = scenario[i])
1733533042958:plot_filename <- paste0("./figures/waterTemp_",scenario[i],".png")
1733533042958:ggplot2::ggsave(p, filename = plot_filename, device = "png",
1733533042958:height = 6, width = 8, units = "in")
1733533042959:}
